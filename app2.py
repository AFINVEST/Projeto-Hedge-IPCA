# DashHedge_rev.py 
# -----------------------------------------------------------------------------
from typing import List
import plotly.graph_objects as go
from datetime import datetime
from pathlib import Path               
import streamlit as st
import streamlit.components.v1 as components
import pandas as pd
import numpy as np
import plotly.graph_objects as go  
import re
import io
from typing import Dict, List, Tuple
from plotnine import (
    ggplot, aes, geom_col, labs, theme, element_text, element_rect,
    scale_fill_manual, geom_text, geom_line, geom_point,
    scale_color_identity, geom_label
)

import io
from os import PathLike

import datetime as dt
import os

POS_FILE = "Dados/hist_posicoes_fundos.csv"
CARTEIRA_DIR = Path("Dados_Carteira")  # ‚Üê pasta que voc√™ criou
RECENT_PARQ = CARTEIRA_DIR / "carteira_recente.parquet"
TODAY_PARQ = CARTEIRA_DIR / "carteira_hoje.parquet"

# Preciso desenvolver
def _hoje() -> str:
    return dt.date.today().strftime("%Y-%m-%d")


def carregar_hist() -> pd.DataFrame:
    if os.path.exists(POS_FILE):
        return pd.read_csv(POS_FILE)
    # estrutura: Fundo ‚Ä¢ Ativo ‚Ä¢ lag ‚Ä¢ curr
    return pd.DataFrame(columns=["Fundo", "Ativo", "lag", "curr"])


def salvar_posicao(df_fundo: pd.DataFrame) -> None:
    """
    Recebe DataFrame j√° filtrado para 1 fundo (colunas Fundo, Ativo, Quantidade).
    Atualiza arquivo mantendo lag/curr.
    """
    hist = carregar_hist()
    fundo = df_fundo["Fundo"].iloc[0]
    hoje = _hoje()

    base = df_fundo[["Fundo", "Ativo", "Quantidade"]].copy()
    base.rename(columns={"Quantidade": "curr"}, inplace=True)
    base["lag"] = None          # placeholder ‚Äì j√° ser√° preenchido do hist

    # extrai linha antiga (dia anterior)
    antigo = hist[hist["Fundo"] == fundo].copy()

    # junta / atualiza lag
    if not antigo.empty:
        base = base.merge(antigo[["Fundo", "Ativo", "curr"]]
                          .rename(columns={"curr": "lag"}),
                          on=["Fundo", "Ativo"], how="left")

    # remove registros antigos desse fundo e inclui os novos
    hist = hist[hist["Fundo"] != fundo]
    hist = pd.concat([hist, base], ignore_index=True)
    hist.to_csv(POS_FILE, index=False)


def comparar_posicoes(fundo: str, ativos_atual: list[str]) -> dict[str, list[str]]:
    """
    Devolve {'faltando':[...], 'novos':[...]} comparando curr vs lag.
    """
    hist = carregar_hist()
    ant = hist[hist["Fundo"] == fundo]["Ativo"].tolist()
    falt = sorted(list(set(ant) - set(ativos_atual)))
    novos = sorted(list(set(ativos_atual) - set(ant)))
    return {"faltando": falt, "novos": novos}


def make_div1_lookup() -> pd.DataFrame:
    """

    L√™ as duas tabelas de deb√™ntures *est√°ticas* (deb_table_completa2 / 3),
    devolve um lookup     Ativo | DV01_UNIT
    (√© barato: ~60 ms, mas cacheamos 4 h nos session_state).

    """
    if "dv01_lookup" in st.session_state:
        return st.session_state["dv01_lookup"]

    bases = []
    for csv in ["Dados/deb_table_completa2.csv",
                "Dados/deb_table_completa3.csv"]:
        df = pd.read_csv(csv)

        # nomes fixos
        df.columns = ["Evento", "Data_pgto", "Prazo_√∫til", "Dias_btwn",
                      "Exp_pct", "Juros_proj", "Amort", "Fluxo_desc",
                      "Ativo"]
        df["Fluxo_desc"] = (df["Fluxo_desc"].astype(str)
                            .str.replace(".", "", regex=False)
                            .str.replace(",", ".")
                            .astype(float))
        df["Prazo_√∫til"] = pd.to_numeric(df["Prazo_√∫til"], errors="coerce")

        bases.append(df[["Ativo", "Fluxo_desc", "Prazo_√∫til"]])

    base = (pd.concat(bases, ignore_index=True)
              .drop_duplicates("Ativo")            # 1 linha por ativo
              .assign(Ativo=lambda d: d["Ativo"].str.upper().str.strip()))

    base["DV01_UNIT"] = (
        base["Fluxo_desc"] * 0.0001 * (base["Prazo_√∫til"] / 252)
    )
    st.session_state["dv01_lookup"] = base[["Ativo", "DV01_UNIT"]]
    return st.session_state["dv01_lookup"]


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ FUN√á√ïES DE CARGA ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def load_carteira_hoje() -> pd.DataFrame:
    """L√™ carteira_hoje.parquet e devolve colunas: Data, Fundo, Ativo,
       Estrat√©gia, Quantidade (capitaliza√ß√£o certa)."""
    
    # df = (pd.read_parquet(TODAY_PARQ)
    #        .rename(columns={"data":"Data",
    #                         "fundo":"Fundo",
    #                         "ativo":"Ativo",
    #                         "estrategia":"Estrat√©gia",
    #                         "quantidade":"Quantidade"}))

    df = pd.read_excel('Dados/Relat√≥rio de Posi√ß√£o 2026-01-26.xlsx')

    # se precisar de 'Valor' em algum ponto mais √† frente:
    if "Valor" not in df.columns:
        df["Valor"] = 0.0
    
    return df


def load_carteira_recent() -> pd.DataFrame:

    """
    √öltimos 3 meses.  Agora j√° volta *com* DIV1_ATIVO di√°rio.
    """

    df = pd.read_parquet(RECENT_PARQ).rename(columns={
        "data": "Data", "fundo": "Fundo", "ativo": "Ativo",
        "estrategia": "Estrat√©gia", "quantidade": "Quantidade"
    })

    # ‚ñ∏ transforma datas / limpa fins-de-semana
    df["Data"] = pd.to_datetime(df["Data"])
    df = df[df["Data"].dt.dayofweek < 5]           # 0-4 = dias √∫teis

    # ‚ñ∏ DV01 unit√°rio por ativo (lookup est√° em cache 4 h)
    lk = make_div1_lookup()
    df = (df.assign(Ativo=lambda d: d["Ativo"].str.upper().str.strip())
            .merge(lk, on="Ativo", how="left"))

    # ‚ñ∏ se n√£o achar o ativo na tabela, DV01_UNIT‚Üí0 (peso 0)
    df["DV01_UNIT"].fillna(0, inplace=True)

    # ‚ñ∏ finalmente o peso di√°rio
    df["DIV1_ATIVO"] = df["Quantidade"] * df["DV01_UNIT"]

    # campo Valor √†s vezes faz falta nas telas antigas
    if "Valor" not in df.columns:
        df["Valor"] = 0.0

    return df[["Data", "Fundo", "Ativo", "Estrat√©gia",
               "Quantidade", "Valor", "DIV1_ATIVO"]]


###############################################################################
# CONFIGURA√á√ÉO GERAL
###############################################################################
st.set_page_config(
    page_title="DashHedge ‚Äì Dashboard de An√°lise de Hedge",
    layout="wide",
    initial_sidebar_state="expanded",
)

################################################################################
# FUN√á√ïES AUXILIARES ‚Äì NOVAS
################################################################################


def _normalizar_ticker_dap(tk: str) -> str:
    """Converte algo como 'DAPAGO30'  ‚Üí  'DAP30'. Mant√©m 'DAP25' intacto."""
    if not isinstance(tk, str) or not tk.startswith("DAP"):
        return None
    m = re.search(r"DAP.*?(\d{2})$", tk)
    return f"DAP{m.group(1)}" if m else None


def process_dap_counts(df_posicao_raw: pd.DataFrame) -> Tuple[pd.DataFrame, pd.DataFrame]:
    # ---------------------------------------------------------------------
    # 1) Seleciona apenas DAPs que j√° s√£o Hedge‚ÄêIPCA
    # ---------------------------------------------------------------------
    mask_dap = df_posicao_raw["Ativo"].astype(
        str).str.startswith("DAP", na=False)
    mask_estr = df_posicao_raw["Estrat√©gia"].astype(
        str).str.contains("Hedge IPCA", na=False)
    df_dap = df_posicao_raw[mask_dap & mask_estr].copy()

    # ---------------------------------------------------------------------
    # 2) ‚ñ∫ NOVO ‚Äì extrai a quantidade que est√° dentro da string ‚ÄúHedge IPCA (‚Ä¶)‚Äù
    # ---------------------------------------------------------------------
    mask_qtd = df_dap["Estrat√©gia"].str.contains(r"Hedge IPCA\s*\(", na=False)
    df_dap.loc[mask_qtd, "Quantidade"] = (
        df_dap.loc[mask_qtd, "Estrat√©gia"]
        # pega o n√∫mero entre par√™nteses
        .str.extract(r"Hedge IPCA\s*\(\s*([-+]?\d+)\s*\)")[0]
        .astype(int)
    )

    # ---------------------------------------------------------------------
    # 3) Continua igual: normaliza ticker, garante num√©rico, faz os groupbys
    # ---------------------------------------------------------------------
    df_dap["DAP"] = df_dap["Ativo"].apply(_normalizar_ticker_dap)
    df_dap.dropna(subset=["DAP"], inplace=True)

    # caso tenha linhas cujo ‚ÄúQuantidade‚Äù ainda esteja vazio, zera-as
    df_dap["Quantidade"] = pd.to_numeric(
        df_dap["Quantidade"], errors="coerce").fillna(0)

    by_fundo = df_dap.groupby(["Fundo", "DAP"], as_index=False)[
        "Quantidade"].sum()
    total = df_dap.groupby("DAP",          as_index=False)["Quantidade"].sum()
    return by_fundo, total


################################################################################
# FUN√á√ïES DE CARGA / PROCESSAMENTO (bases originais + DAP extra)
################################################################################

def _prep_spread_df2(path: str | PathLike) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    L√™ o Excel de spreads (Planilha2) e devolve:
        ‚Ä¢ df_melt ‚Äì longo, p/ gr√°fico em linha (Spread √ó Data)
        ‚Ä¢ df_vert ‚Äì wide -> longo p/ gr√°fico Vertice √ó Spread (um dia)
    """
    dados = pd.read_excel(path, sheet_name="Planilha6")

    # renomeia & filtra zeros
    cols = ['DATA', 'DAP25', 'DAP26', 'DAP27', 'DAP28', 'DAP30', 'DAP32', 'DAP35', 'DAP40',
            'NTNB25', 'NTNB26', 'NTNB27', 'NTNB28', 'NTNB30', 'NTNB32', 'NTNB33', 'NTNB35', 'NTNB40', 'NTNB45', 'NTNB50', 'NTNB60']
    dados.columns = cols
    for c in cols[1:]:
        dados = dados[dados[c] != 0]

    # calcula spreads
    for y in ["25", "26", "27", "28", "30", "32", "33", "35", "40", "45", "50", "60"]:
        dados[f"Spread B{y}/DAP{y}"] = dados[f"NTNB{y}"] - dados[f"DAP{y}"]
    dados_diff = dados.filter(regex=r"^DATA$|^Spread").copy()

    # -------- DF para gr√°fico em linha -------- #
    df_melt = (
        dados_diff
        .melt(id_vars="DATA", var_name="Tipo", value_name="Spread")
        .assign(Data_Str=lambda x: x["DATA"].dt.strftime("%Y-%m-%d"))
    )

    cores = {
        'Spread B25/DAP25': '#003366',
        'Spread B26/DAP26': '#1f77b4',
        'Spread B27/DAP27': '#2ca02c',
        'Spread B28/DAP28': '#d62728',
        'Spread B30/DAP30': '#9467bd',
        'Spread B32/DAP32': '#8c564b',
        'Spread B35/DAP35': '#e377c2',
        'Spread B40/DAP40': '#7f7f7f',
        'Spread B45/DAP45': '#bcbd22',
        'Spread B50/DAP50': '#17becf',
        'Spread B60/DAP60': '#ff7f0e',
        'Spread B33/DAP33': '#ffbb78',
    }

    df_melt["Color"] = df_melt["Tipo"].map(cores)

    # -------- DF para gr√°fico Spread (Y) √ó V√©rtice (X) -------- #
    df_vert = (
        dados_diff.set_index("DATA")
        .pipe(lambda df_: df_.assign(**{c.split()[1]: df_[c] for c in df_.columns}))
        .drop(columns=dados_diff.columns[1:])              # s√≥ as novas cols
        .reset_index()
        .melt(id_vars="DATA", var_name="Vertice", value_name="Spread")
        .assign(Vertice=lambda x: x["Vertice"].str[-2:].astype(int))  # 25,26,‚Ä¶
    )
    return df_melt, df_vert


def _prep_spread_df(path: str | PathLike) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    L√™ o Excel de spreads (Planilha2) e devolve:
        ‚Ä¢ df_melt ‚Äì longo, p/ gr√°fico em linha (Spread √ó Data)
        ‚Ä¢ df_vert ‚Äì wide -> longo p/ gr√°fico Vertice √ó Spread (um dia)
    """
    dados = pd.read_excel(path, sheet_name="Planilha2")

    # renomeia & filtra zeros
    cols = ['DATA', 'DAP26', 'DAP27', 'DAP28', 'DAP30', 'DAP32', 'DAP35', 'DAP40',
            'NTNB26', 'NTNB27', 'NTNB28', 'NTNB30', 'NTNB32', 'NTNB35', 'NTNB40']
    dados.columns = cols
    for c in cols[1:]:
        dados = dados[dados[c] != 0]

    # calcula spreads
    for y in ["26", "27", "28", "30", "32", "35", "40"]:
        dados[f"Spread B{y}/DAP{y}"] = dados[f"NTNB{y}"] - dados[f"DAP{y}"]
    dados_diff = dados.filter(regex=r"^DATA$|^Spread").copy()

    # -------- DF para gr√°fico em linha -------- #
    df_melt = (
        dados_diff
        .melt(id_vars="DATA", var_name="Tipo", value_name="Spread")
        .assign(Data_Str=lambda x: x["DATA"].dt.strftime("%Y-%m-%d"))
    )

    cores = {
        # 'Spread B25/DAP25': '#003366',
        'Spread B26/DAP26': '#1f77b4',
        'Spread B27/DAP27': '#2ca02c',
        'Spread B28/DAP28': '#d62728',
        'Spread B30/DAP30': '#9467bd',
        'Spread B32/DAP32': '#8c564b',
        'Spread B35/DAP35': '#e377c2',
        'Spread B40/DAP40': '#7f7f7f',
    }
    df_melt["Color"] = df_melt["Tipo"].map(cores)

    # -------- DF para gr√°fico Spread (Y) √ó V√©rtice (X) -------- #
    df_vert = (
        dados_diff.set_index("DATA")
        .pipe(lambda df_: df_.assign(**{c.split()[1]: df_[c] for c in df_.columns}))
        .drop(columns=dados_diff.columns[1:])              # s√≥ as novas cols
        .reset_index()
        .melt(id_vars="DATA", var_name="Vertice", value_name="Spread")
        .assign(Vertice=lambda x: x["Vertice"].str[-2:].astype(int))  # 25,26,‚Ä¶
    )
    return df_melt, df_vert


def _prep_ntnb_df(path: str | PathLike) -> pd.DataFrame:
    """
    DATA | B_REF | NTNB_YIELD   (DATA em datetime64[ns])
    """
    dados = pd.read_excel(path, sheet_name="Planilha6")

    nt_cols = ['NTNB25', 'NTNB26', 'NTNB27', 'NTNB28', 'NTNB29',
               'NTNB30', 'NTNB32', 'NTNB33', 'NTNB35', 'NTNB40', 'NTNB45',
               'NTNB50', 'NTNB55', 'NTNB60']
    dados = dados[['DATA'] + nt_cols].copy()
    dados.columns = ['DATA'] + nt_cols

    dados["DATA"] = pd.to_datetime(dados["DATA"])     # ‚Üê convers√£o expl√≠cita

    nt_long = (dados
               .melt(id_vars='DATA', var_name='NTNB', value_name='NTNB_YIELD')
               .dropna()
               .assign(B_REF=lambda x: x['NTNB'].str.replace('NTNB', 'B'))
               .drop(columns='NTNB')
               .sort_values(['B_REF', 'DATA'])
               )
    # Substitui zeros por NaN e faz forward fill por grupo de B_REF
    nt_long['NTNB_YIELD'] = (
        nt_long
        .groupby('B_REF')['NTNB_YIELD']
        .transform(lambda x: x.replace(0, np.nan).ffill())
    )
    return nt_long


if "df_ntnb_long" not in st.session_state:
    st.session_state["df_ntnb_long"] = _prep_ntnb_df("Dados/BBG - ECO DASH_te.xlsx")


def process_df() -> pd.DataFrame:
    """Carrega posi√ß√£o + deb√™ntures e devolve df_posicao_juros j√° agregado.
    Tamb√©m armazena em session_state:
        ‚Ä¢ df_extras            ‚Äì ativos IPCA fora da carteira
        ‚Ä¢ dap_counts_by_fundo  ‚Äì contratos DAP hedge j√° existentes por fundo
        ‚Ä¢ dap_counts_total     ‚Äì contratos DAP hedge j√° existentes consolidados
    """
    # --- Posi√ß√£o completa (sem filtros) --------------------------------------
    df_posicao_raw = load_carteira_hoje()
    st.session_state["df_posicao_raw"] = df_posicao_raw.copy()

    # ================================================================
    # 1.¬†Processa DAPs j√° existentes (antes de qualquer filtro)
    # ================================================================
    counts_by_fundo, counts_total = process_dap_counts(df_posicao_raw)
    st.session_state["dap_counts_by_fundo"] = counts_by_fundo
    st.session_state["dap_counts_total"] = counts_total

    # ----------------------------------------------------------------
    # 2.¬†Fluxos de deb√™ntures conforme vers√£o anterior
    # ----------------------------------------------------------------
    df_debentures = pd.read_csv("Dados/deb_table_completa2.csv")

    for col in ["Juros projetados", "Fluxo descontado (R$)", "Amortiza√ß√µes"]:
        df_debentures[col] = (
            df_debentures[col]
            .str.replace("-", "0")
            .str.replace(".", "", regex=False)
            .str.replace(",", ".")
            .astype(float)
        )

    ativos = obter_lista_ativos_original() + obter_lista_outros_original()
    dap_dict = obter_dap_dict_original()

    # ----------------------------------------------------------------
    # 2.1¬†Filtra df_posicao para exposi√ß√£o das deb√™ntures (mant√©m counts DAP
    # ¬†¬†¬†¬†¬†intocados em session_state)
    # ----------------------------------------------------------------
    df_posicao = df_posicao_raw[df_posicao_raw["Ativo"].isin(ativos)].copy()

    # --- restante da rotina original (formata√ß√£o + merge) --------------------
    df_debentures.columns = [
        "Dados do evento", "Data de pagamento", "Prazos (dias √∫teis)",
        "Dias entre pagamentos", "Expectativa de juros (%)", "Juros projetados",
        "Amortiza√ß√µes", "Fluxo descontado (R$)", "Ativo",
    ]
    df_debentures = df_debentures[df_debentures["Ativo"].isin(
        df_posicao["Ativo"])]

    df_debentures["Data de pagamento"] = pd.to_datetime(
        df_debentures["Data de pagamento"])
    df_debentures["Data"] = df_debentures["Data de pagamento"].dt.strftime(
        "%Y-%m")
    df_debentures["Ano"] = df_debentures["Data de pagamento"].dt.year
    df_debentures["Semestre"] = (
        df_debentures["Data de pagamento"].dt.quarter.replace(
            {1: "1¬∫ Semestre", 2: "1¬∫ Semestre", 3: "2¬∫ Semestre", 4: "2¬∫ Semestre"})
    )
    df_quant = (df_posicao
                .groupby(["Fundo", "Ativo"], as_index=False)
                .agg({"Quantidade": "sum", "Valor": "sum"}))
    df_quant["Valor"] = (
        df_quant["Valor"].astype(str).str.replace(",", ".").astype(float)
    )

    df_debentures.drop(columns=["Data de pagamento"], inplace=True)

    df_merged = pd.merge(df_debentures, df_quant, on="Ativo", how="left")
    df_merged["Juros projetados"] = df_merged["Fluxo descontado (R$)"] * \
        df_merged["Quantidade"]
    df_merged["Amortiza√ß√µes"] = df_merged["Amortiza√ß√µes"] * \
        df_merged["Quantidade"]
    df_merged["DIV1_ATIVO"] = df_merged["Juros projetados"] * \
        0.0001 * (df_merged["Prazos (dias √∫teis)"] / 252)
    df_merged["DAP"] = df_merged["Ano"].map(dap_dict)

    # ----------------------------------------------------------------
    # 3.¬†Ativos extras (df_debentures2) ‚Äì permanece igual
    # ----------------------------------------------------------------
    df_debentures2 = pd.read_csv("Dados/deb_table_completa3.csv")
    for col in ["Juros projetados", "Fluxo descontado (R$)", "Amortiza√ß√µes"]:
        df_debentures2[col] = (
            df_debentures2[col]
            .str.replace("-", "0")
            .str.replace(".", "", regex=False)
            .str.replace(",", ".")
            .astype(float)
        )
    df_debentures2.columns = [
        "Dados do evento", "Data de pagamento", "Prazos (dias √∫teis)",
        "Dias entre pagamentos", "Expectativa de juros (%)", "Juros projetados",
        "Amortiza√ß√µes", "Fluxo descontado (R$)", "Ativo",
    ]
    df_debentures2["Data de pagamento"] = pd.to_datetime(
        df_debentures2["Data de pagamento"])
    df_debentures2["Data"] = df_debentures2["Data de pagamento"].dt.strftime(
        "%Y-%m")
    df_debentures2["Ano"] = df_debentures2["Data de pagamento"].dt.year
    df_debentures2["Semestre"] = (
        df_debentures2["Data de pagamento"].dt.quarter.replace(
            {1: "1¬∫ Semestre", 2: "1¬∫ Semestre", 3: "2¬∫ Semestre", 4: "2¬∫ Semestre"})
    )
    df_debentures2 = df_debentures2[~df_debentures2["Ativo"].isin(
        df_debentures["Ativo"].unique())]

    df_debentures2["Quantidade"] = 100
    df_debentures2["Fundo"] = "SEM FUNDO"
    df_debentures2["Juros projetados"] = df_debentures2[
        "Fluxo descontado (R$)"] * df_debentures2["Quantidade"]
    df_debentures2["Amortiza√ß√µes"] = df_debentures2["Amortiza√ß√µes"] * \
        df_debentures2["Quantidade"]
    df_debentures2["DIV1_ATIVO"] = df_debentures2["Juros projetados"] * \
        0.0001 * (df_debentures2["Prazos (dias √∫teis)"] / 252)
    df_debentures2["DAP"] = df_debentures2["Ano"].map(dap_dict)

    st.session_state["df_extras"] = df_debentures2.copy()

    # sa√≠da final da fun√ß√£o
    return df_merged.rename(columns={"Data": "Data de pagamento"})


def process_div01() -> pd.DataFrame:
    df_div1 = pd.read_excel("Dados/AF_Trading.xlsm",
                            sheet_name="Base IPCA", skiprows=16)
    df_div1 = df_div1.iloc[:, :13].dropna()[["DAP", "DV01"]]
    df_div1["DAP"] = df_div1["DAP"].apply(
        lambda x: x[:3] + x[-2:] if isinstance(x, str) and len(x) >= 5 else x)
    return df_div1


def obter_lista_ativos_original() -> List[str]:
    return ['RALM21', 'ACRC21', 'AEAB11', 'AEGP23', 'AESL17', 'AESLA5', 'AESLA7', 'AESLA9', 'AESLB7', 'AESOA1', 'AGVF12', 'AHGD13', 'ALGA27', 'ALGAB1', 'ALGAC2', 'ALGE16', 'ALGTA4', 'ALIG12', 'ALIG13', 'ALIG15', 'ALUP18', 'ANET11', 'ANET12', 'APFD19', 'APPSA2', 'APRB18', 'ARTR19', 'ASAB11', 'ASCP13', 'ASCP23', 'ASER12', 'ASSR21', 'ATHT11', 'ATII12', 'AURE12', 'BARU11', 'BCPSA5', 'BHSA11', 'BLMN12', 'BRFS31', 'BRKP28', 'BRST11', 'CAEC12', 'CAEC21', 'CAJS11', 'CAJS12', 'CART13', 'CASN23', 'CBAN12', 'CBAN32', 'CBAN52', 'CBAN72', 'CCLS11', 'CCROA5', 'CCROB4', 'CCROB6', 'CDES11', 'CEAD11', 'CEAP12', 'CEAP14', 'CEAP17', 'CEAR26', 'CEEBA1', 'CEEBB6', 'CEEBB7', 'CEEBC3', 'CEEBC4', 'CEED12', 'CEED13', 'CEED15', 'CEED17', 'CEED21', 'CEMT19', 'CEPE19', 'CEPEB3', 'CEPEC1', 'CEPEC2', 'CESE32', 'CESPA2', 'CESPA3', 'CGASA1', 'CGASA2', 'CGASB1', 'CGMG18', 'CGOS13', 'CGOS16', 'CGOS24', 'CGOS28', 'CGOS34', 'CHSF13', 'CJEN13', 'CLAG13', 'CLCD26', 'CLCD27', 'CLNG11', 'CLTM14', 'CMGD27', 'CMGD28', 'CMGDB0', 'CMGDB1', 'CMIN11', 'CMIN12', 'CMIN21', 'CMIN22', 'CMTR29', 'CNRD11', 'COCE18', 'COMR14', 'COMR15', 'CONF11', 'CONX12', 'CPFGA2', 'CPFPA0', 'CPFPA5', 'CPFPA7', 'CPFPB7', 'CPGT15', 'CPGT26', 'CPGT27', 'CPGT28', 'CPLD15', 'CPLD26', 'CPLD29', 'CPLD37', 'CPTM15', 'CPXB22', 'CRMG15', 'CRTR12', 'CSAN33', 'CSMGA2', 'CSMGA6', 'CSMGB4', 'CSMGB8', 'CSMGB9', 'CSMGC3', 'CSNAA4', 'CSNAA5', 'CSNAA6', 'CSNAB4', 'CSNAB5', 'CSNAB6', 'CSNAC4', 'CSNP12', 'CSRN19', 'CSRN29', 'CSRNA1', 'CSRNB2', 'CSRNC0', 'CTEE17', 'CTEE18', 'CTEE1B', 'CTEE29', 'CTEE2B', 'CTGE11', 'CTGE13', 'CTGE15', 'CTNS14', 'CTRR11', 'CUTI11', 'CXER12', 'DESK17', 'EBAS13', 'EBENA8', 'ECER12', 'ECHP11', 'ECHP12', 'ECHP22', 'ECOV16', 'ECPN11', 'EDFT11', 'EDPA11', 'EDPT11', 'EDTE12', 'EDVP14', 'EDVP17', 'EEELA0', 'EEELA1', 'EEELB1', 'EGIE17', 'EGIE19', 'EGIE27', 'EGIE29', 'EGIE39', 'EGIE49', 'EGIEA0', 'EGIEA1', 'EGIEB1', 'EGIEB2', 'EGVG11', 'EGVG21', 'EKTRB3', 'EKTRC0', 'EKTRC1', 'EKTT11', 'ELEK37', 'ELET14', 'ELET16', 'ELET23', 'ELET42', 'ELPLA5', 'ELPLA7', 'ELPLB4', 'ELTN15', 'ENAT11', 'ENAT12', 'ENAT13', 'ENAT14', 'ENAT24', 'ENAT33', 'ENERA1', 'ENERB4', 'ENEV13', 'ENEV15', 'ENEV16', 'ENEV18', 'ENEV19', 'ENEV26', 'ENEV28', 'ENEV29', 'ENEV32', 'ENEV39', 'ENEVA0', 'ENEVB0', 'ENGI39', 'ENGIA1', 'ENGIA4', 'ENGIA5', 'ENGIA6', 'ENGIA9', 'ENGIB0', 'ENGIB2', 'ENGIB4', 'ENGIB6', 'ENGIB9', 'ENGIC0', 'ENJG21', 'ENMI21', 'ENMTA3', 'ENMTA4', 'ENMTA5', 'ENMTA7', 'ENMTB3', 'ENMTB5', 'ENSEA1', 'ENTV12', 'EQMAA0', 'EQMAA2', 'EQPA18', 'EQSP11', 'EQSP21', 'EQTC11', 'EQTN11', 'EQTR11', 'EQTR21', 'EQTS11', 'EQUA11', 'ERDV17', 'ERDV38', 'ERDVA4', 'ERDVB4', 'ERDVC3', 'ERDVC4', 'ESAM14', 'ESULA1', 'ESULA6', 'ETAP22', 'ETBA12', 'ETEN11', 'ETEN12', 'ETEN21', 'ETEN22', 'ETEN31', 'ETSP12', 'EUBE11', 'EXTZ11', 'FBRI13', 'FGEN13', 'FLCLA0', 'FRAG14', 'FURN21', 'GASC15', 'GASC16', 'GASC17', 'GASC22', 'GASC23', 'GASC25', 'GASC26', 'GASC27', 'GASP19', 'GASP29', 'GASP34', 'GBSP11', 'GEPA28', 'GRRB24', 'GSTS14', 'GSTS24', 'HARG11', 'HBSA11', 'HBSA21', 'HGLB23', 'HVSP11', 'HZTC14', 'IBPB11', 'IGSN15', 'IRJS14', 'IRJS15', 'ITPO14', 'IVIAA0', 'JALL11', 'JALL13', 'JALL14', 'JALL15', 'JALL21', 'JALL24', 'JSMLB5', 'JTEE11', 'JTEE12', 'KLBNA5', 'LCAMD1', 'LCAMD3', 'LGEN11', 'LORTA7', 'LSVE39', 'LTTE15', 'MEZ511', 'MGSP12', 'MNAU13', 'MOVI18', 'MOVI37', 'MRSAA1', 'MRSAA2', 'MRSAB1', 'MRSAB2', 'MRSAC1', 'MRSAC2', 'MSGT12', 'MSGT13', 'MSGT23', 'MSGT33', 'MTRJ19', 'MVLV16', 'NEOE16', 'NEOE26', 'NMCH11', 'NRTB11', 'NRTB21', 'NTEN11', 'ODTR11', 'ODYA11', 'OMGE12', 'OMGE22', 'OMGE31', 'OMGE41', 'OMNG12', 'ORIG11', 'PALF38', 'PALFA3', 'PALFB3', 'PASN12', 'PEJA11', 'PEJA22', 'PEJA23', 'PETR16', 'PETR17', 'PETR26', 'PETR27', 'PLSB1A', 'POTE11', 'POTE12', 'PPTE11', 'PRAS11', 'PRPO12', 'PRTE12', 'PTAZ11', 'QUAT13', 'RAHD11', 'RAIZ13', 'RAIZ23', 'RATL11', 'RDOE18', 'RDVE11', 'RECV11', 'RESA14', 'RESA15', 'RESA17', 'RESA27', 'RIGEA3', 'RIPR22', 'RIS412', 'RIS414', 'RIS422', 'RIS424', 'RISP12', 'RISP14', 'RISP22', 'RISP24', 'RMSA12', 'RRRP13', 'RSAN16', 'RSAN26', 'RSAN34', 'RSAN44', 'RUMOA2', 'RUMOA3', 'RUMOA4', 'RUMOA5', 'RUMOA6', 'RUMOA7', 'RUMOB1', 'RUMOB3', 'RUMOB5', 'RUMOB6', 'RUMOB7', 'SABP12', 'SAELA1', 'SAELA3', 'SAELB3', 'SAPR10', 'SAPRA2', 'SAPRA3', 'SAPRB3', 'SAVI13', 'SBSPB6', 'SBSPC4', 'SBSPC6', 'SBSPD4', 'SBSPE3', 'SBSPE9', 'SBSPF3', 'SBSPF9', 'SERI11', 'SMTO14', 'SMTO24', 'SNRA13', 'SPRZ11', 'SRTI11', 'STBP35', 'STBP45', 'STRZ11', 'SUMI17', 'SUMI18', 'SUMI37', 'SUZB19', 'SUZB29', 'SUZBA0', 'SUZBC1', 'TAEB15', 'TAEE17', 'TAEE18', 'TAEE26', 'TAEEA2', 'TAEEA4', 'TAEEA7', 'TAEEB2', 'TAEEB4', 'TAEEC2', 'TAEEC4', 'TAEED2', 'TAES15', 'TBEG11', 'TBLE26', 'TCII11', 'TEPA12', 'TIET18', 'TIET29', 'TIET39', 'TIMS12', 'TNHL11', 'TOME12', 'TPEN11', 'TPNO12', 'TPNO13', 'TRCC11', 'TRGO11', 'TRPLA4', 'TRPLA7', 'TRPLB4', 'TRPLB7', 'TSSG21', 'TVVH11', 'UHSM12', 'UNEG11', 'UNTE11', 'USAS11', 'UTPS11', 'UTPS12', 'UTPS21', 'UTPS22', 'VALE38', 'VALE48', 'VALEA0', 'VALEB0', 'VALEC0', 'VAMO33', 'VAMO34', 'VBRR11', 'VDBF12', 'VDEN12', 'VERO12', 'VERO13', 'VERO24', 'VERO44', 'VLIM13', 'VLIM14', 'VLIM15', 'VLIM16', 'VPLT12', 'VRDN12', 'WDPR11', 'XNGU17']


def obter_lista_outros_original() -> List[str]:
    return [
        "BRFS31", "CRA Ferroeste 2¬™ S√©rie", "CRI Bem Brasil", "NTN-B26", "NTN-B28",
        "NTN-B30", "NTN-B32", "NTN-B50", "CRI Vic Engenharia 1¬™ Emiss√£o", "TBCR18",
        "CRTA12", "CERT11", "CRI PERNAMBUCO 35¬™ (23J1753853)", "CRI Vic Engenharia 2¬™ Emiss√£o", "VALEB1"
    ]


def obter_dap_dict_original() -> Dict[int, str]:
    return {
        2025: "DAP26", 2026: "DAP26", 2027: "DAP27", 2028: "DAP28", 2029: "DAP29",
        2030: "DAP30", 2031: "DAP30", 2032: "DAP32", 2033: "DAP32", 2034: "DAP35",
        2035: "DAP35", 2036: "DAP35", 2037: "DAP35", 2038: "DAP40", 2039: "DAP40",
        2040: "DAP40", 2041: "DAP40", 2042: "DAP40", 2043: "DAP40", 2044: "DAP40", 2045: "DAP40", 2046: "DAP40", 2047: "DAP40", 2048: "DAP40", 2049: "DAP40", 2050: "DAP40", 2051: "DAP40", 2052: "DAP40", 2053: "DAP40", 2054: "DAP40", 2055: "DAP40", 2056: "DAP40", 2057: "DAP40", 2058: "DAP40", 2059: "DAP40", 2060: "DAP40"
    }


###############################################################################
# UTILIT√ÅRIOS DE UI (sem altera√ß√µes exceto import CSS)
###############################################################################

_B_MAP = {   # = mesmo crit√©rio que voc√™ usa p/ DAPs
    2025: 'B25', 2026: 'B26', 2027: 'B27', 2028: 'B28', 2029: 'B29',
    2030: 'B30', 2031: 'B30', 2032: 'B32', 2033: 'B32', 2034: 'B35',
    2035: 'B35', 2036: 'B35', 2037: 'B35', 2038: 'B40', 2039: 'B40',
    2040: 'B40', 2041: 'B40', 2042: 'B40', 2043: 'B40', 2044: 'B40',
}


def _to_B_ref(s: str | float | pd.Timestamp) -> str | None:
    """
    ‚ñ∏ Converte qualquer coisa que apare√ßa na col. **B refer√™ncia** para
      formato can√≥nico 'B25', 'B35', ‚Ä¶  
    ‚ñ∏ Aceita:
        ‚Ä¢ j√° estar como 'B35'
        ‚Ä¢ string-data '15/05/2040'
        ‚Ä¢ datetime / Timestamp
    """
    if pd.isna(s):
        return None
    txt = str(s).strip().upper()

    m = re.fullmatch(r'B(\d{2})', txt)
    if m:                        # j√° no formato correcto
        return f'B{m.group(1)}'

    # tenta parsear como data (dd/mm/yyyy, yyyy-mm-dd‚Ä¶)
    data = pd.to_datetime(txt, dayfirst=True, errors='coerce')
    if pd.notna(data):
        ano = data.year
        return _B_MAP.get(ano)
    
    return None                  # n√£o conseguiu limpar


def load_spreads_afinvest(path="Dados/spreads_afinvest.csv") -> pd.DataFrame:
    df = pd.read_csv(path, sep=";").rename(columns=str.strip)
    df["Ativo"] = df["Ativo"].str.upper().str.strip()
    df["B_REF"] = df["B refer√™ncia"].str.upper().str.strip()
    return df[["Ativo", "B_REF"]]


def _div1_por_fundo(df_posicao: pd.DataFrame,
                    df_lookup:  pd.DataFrame) -> pd.DataFrame:
    """
    ‚ñ∏ junta posi√ß√£o (quantidade) + DIV_ONE e devolve:
       Fundo | B_REF | DIV1_QTD
       onde  DIV1_QTD = quantidade * DIV_ONE
    """
    base = (df_posicao.merge(df_lookup, on='Ativo', how='left')
                      .dropna(subset=['B_REF']))          # fora o que n√£o casar

    base['DIV1_QTD'] = base['Quantidade'] * base['DIV_ONE']
    return (base.groupby(['Fundo', 'B_REF'], as_index=False)
            ['DIV1_QTD'].sum())


def _ultimo_spread_por_B(df_melt: pd.DataFrame) -> pd.Series:
    """
    devolve Series  ‚Ä¢index=B_REF  ‚Ä¢value=spread mais recente
    """
    ult_dia = df_melt['DATA'].max()
    ult = df_melt[df_melt['DATA'] == ult_dia].copy()

    ult['B_REF'] = ult['Tipo'].str.extract(r'B(\d{2})').radd('B')
    return ult.set_index('B_REF')['Spread']


def _spread_medio_por_fundo(df_posicao: pd.DataFrame,
                            df_spreads: pd.DataFrame) -> pd.DataFrame:
    """
    df_posicao precisa conter:
        ‚Ä¢ Fundo, Ativo, DIV1_ATIVO  (j√° calculado no seu df_merged)

    Retorna:
        Fundo | SPREAD_MEDIO_BPS
    """
    base = (df_posicao[["Fundo", "Ativo", "DIV1_ATIVO"]]
            .merge(df_spreads, on="Ativo", how="inner"))

    # remove itens sem DV01 (caso zero / NaN)
    base = base[base["DIV1_ATIVO"] != 0]

    res = (base.groupby("Fundo")
           .apply(lambda g: np.average(g["SPREAD_BPS"],
                                       weights=g["DIV1_ATIVO"]))
           .reset_index(name="SPREAD_MEDIO_BPS"))

    return res.sort_values("SPREAD_MEDIO_BPS")


def check_duplicates(df: pd.DataFrame, label: str):
    dups = df.duplicated(subset=["Ativo", "Data de pagamento"]).sum()
    if dups:
        st.warning(
            f"{label}: Encontradas {dups} linhas duplicadas de (Ativo, Data de pagamento). Revise filtros.")
        # Colocar quais s√£o os ativos duplicados
        ativos_duplicados = df[df.duplicated(
            subset=["Ativo", "Data de pagamento"], keep=False)]
        ativos_duplicados = ativos_duplicados[[
            "Ativo", "Data de pagamento"]].drop_duplicates()
        if st.checkbox("Mostrar ativos duplicados?", key="chk_show_dups"):
            st.write("Ativos duplicados encontrados:")
            st.dataframe(ativos_duplicados)


def filtro_generico(df: pd.DataFrame) -> pd.DataFrame:
    """Permite filtrar por qualquer coluna via sidebar."""
    if st.sidebar.checkbox("Filtrar por coluna", key="chk_filter"):
        col = st.sidebar.selectbox(
            "Coluna para filtrar", df.columns.tolist(), key="sel_col")
        valores = sorted(df[col].unique().tolist())
        escolhidos = st.sidebar.multiselect(
            "Valores:", valores, default=valores, key="vals")
        df = df[df[col].isin(escolhidos)]
    return df

###############################################################################
# VISUALIZA√á√ïES (iguais)
###############################################################################

def plot_relacao_juros(df):
    df_plot = (
        df.groupby(["Ano", "Semestre"], as_index=False)[
            "Juros projetados"].sum()
        .assign(**{"Juros projetados (R$ mil)": lambda x: x["Juros projetados"] / 1_000})
    )
    # Lista de anos √∫nicos no eixo x
    anos = sorted(df_plot["Ano"].unique())
    semestres = df_plot["Semestre"].unique()

    fig = go.Figure()

    for semestre in semestres:
        df_sem = df_plot[df_plot["Semestre"] == semestre]
        fig.add_trace(go.Bar(
            x=df_sem["Ano"],
            y=df_sem["Juros projetados (R$ mil)"],
            name=semestre,
            marker_color="#1F4E79" if semestre == "1¬∫ Semestre" else "#A5C8E1"
        ))

    fig.update_layout(
        barmode="group",  # Equivalente ao position="dodge"
        title="Juros + Amortiza√ß√£o Projetados por Ano/Semestre",
        xaxis_title="Ano",
        yaxis_title="Juros (R$ mil)",
        height=400,
        plot_bgcolor="white",
        xaxis=dict(tickangle=45)
    )

    st.plotly_chart(fig, use_container_width=True)


def plot_div1_layout(df: pd.DataFrame, df_div1: pd.DataFrame, carteira: pd.DataFrame | None = None):
    """Exibe gr√°fico + tabela DIV1/DAP. Se *carteira* fornecido, cruza com
    quantidade j√° existente (coluna 'CARTEIRA')."""

    df_sum = (
        df.groupby("DAP", as_index=False)["DIV1_ATIVO"].sum()
        .merge(df_div1, on="DAP", how="left")
        .rename(columns={"DV01": "DV01_DAP"})
    )
    
    df_sum["CONTRATOS"] = df_sum["DIV1_ATIVO"] / df_sum["DV01_DAP"]

    # -----------------------------------------------------------
    # ‚ñº¬†Integra contratos j√° na carteira
    # -----------------------------------------------------------
    if carteira is not None and not carteira.empty:
        cartera_norm = carteira.copy()
        cartera_norm["DAP"] = cartera_norm["DAP"].astype(str)
        df_sum = df_sum.merge(cartera_norm, on="DAP", how="left")
        df_sum.rename(columns={"CARTEIRA": "CARTEIRA"}, inplace=True)
        df_sum["CARTEIRA"].fillna(0, inplace=True)
        df_sum["FALTAM"] = df_sum["CONTRATOS"] + df_sum["CARTEIRA"]

    # -----------------------------------------------------------
    # ‚ñ∫¬†Gr√°fico ‚Äì DIV1 por DAP (mantido)
    # -----------------------------------------------------------
    col1, col2, col3 = st.columns([4.9, 0.2, 4.9])
    with col1:
        p1 = (
            ggplot(df_sum, aes(x="DAP", y="DIV1_ATIVO"))
            + geom_col(fill="#1F4E79")
            + geom_text(aes(label=df_sum["DIV1_ATIVO"].apply(
                lambda x: f"{x:,.0f}")), va="bottom", size=8)
            + labs(title="DIV1 vs DAP", x="DAP", y="DIV1 (R$)")
            + theme(figure_size=(6, 4), axis_text_x=element_text(rotation=45, ha="right"),
                    panel_background=element_rect(fill="white"))
        )
        st.pyplot(p1.draw(), use_container_width=True)

    with col2:
        st.html(
            "<div style='border-left:2px solid rgba(49,51,63,0.2);height:60vh;margin:auto'></div>")

    with col3:
        #df_fmt = df_sum.copy()
        ## Arredonda CONTRATOS
        #df_fmt["CONTRATOS"] = df_fmt["CONTRATOS"].round().astype(int)
        ## if "CARTEIRA" in df_fmt.columns:
        ##    df_fmt["CARTEIRA"] = df_fmt["CARTEIRA"].round().astype(int)
        ##    df_fmt["FALTAM"] = df_fmt["FALTAM"].round().astype(int)
        #df_fmt.set_index("DAP", inplace=True)
#
        ## Totais
        #totais = df_fmt.sum(numeric_only=True)
        #df_fmt.loc["Total"] = totais
#
        ## Formata√ß√£o
        #sty = df_fmt.style.format("{:,.0f}")
        #sty = sty.set_table_styles([
        #    {"selector": "th", "props": [
        #        ("font-weight", "bold"), ("text-align", "center")]},
        #    {"selector": "td", "props": [("text-align", "right")]},
        #    {"selector": "caption", "props": [
        #        ("font-size", "16px"), ("font-weight", "bold")]},
        #])
        #st.table(sty.set_caption("Tabela de DAPs: Necess√°rio √ó Carteira"))
        df_fmt = df_sum.copy()
        df_fmt.set_index("DAP", inplace=True)

        # Totais (sem arredondar)
        totais = df_fmt.sum(numeric_only=True)
        df_fmt.loc["Total"] = totais

        # ===== TABELA =====
        sty = (
            df_fmt.style
            .format({
                "DIV1_ATIVO": "{:,.4f}",
                "DV01_DAP": "{:,.6f}",
                "CONTRATOS": "{:,.4f}",
                "CARTEIRA": "{:,.4f}",
                "FALTAM": "{:,.4f}",
            })
            .set_table_styles([
                {"selector": "th", "props": [("font-weight", "bold"), ("text-align", "center")]},
                {"selector": "td", "props": [("text-align", "right")]},
            ])
        )

        st.table(sty)

        # ===== EXPORTA√á√ÉO EXCEL =====
        def _to_excel_bytes(df: pd.DataFrame) -> bytes:
            buf = io.BytesIO()
            with pd.ExcelWriter(buf, engine="openpyxl") as writer:
                df.to_excel(writer, sheet_name="DAP_DIV1", merge_cells=False)
            return buf.getvalue()

        st.download_button(
            label="üì• Baixar tabela em Excel",
            data=_to_excel_bytes(df_fmt),
            file_name="tabela_dap_div1.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        )

    # Retorna apenas DAP/CONTRATOS (p/ rotina de salvar posi√ß√£o)
    return df_sum[["DAP", "CONTRATOS"]].set_index("DAP")


def atualizar_session_state_contratos(fundo: str, df_contr: pd.DataFrame):
    if "df_total" not in st.session_state:
        st.session_state.df_total = pd.DataFrame()

    st.subheader("Pr√©-visualiza√ß√£o dos contratos")
    st.table(df_contr.style.format("{:,.0f}"))

    overwrite = st.checkbox("Sobrescrever se j√° existir", key=f"ovw_{fundo}")

    def _salvar():
        if fundo in st.session_state.df_total.columns and not overwrite:
            st.warning(
                "Coluna j√° existente. Marque 'Sobrescrever' para substituir.")
            return
        if fundo in st.session_state.df_total.columns and overwrite:
            st.session_state.df_total.drop(columns=[fundo], inplace=True)
        st.session_state.df_total = st.session_state.df_total.add(
            df_contr.rename(columns={"CONTRATOS": fundo}), fill_value=0)
        st.success("Posi√ß√£o salva!")

    st.button("Salvar posi√ß√£o", on_click=_salvar, key=f"btn_save_{fundo}")

    # Exclus√£o de coluna espec√≠fica
    if not st.session_state.df_total.empty:
        st.subheader("Posi√ß√µes acumuladas")
        df_plot = st.session_state.df_total.copy()
        df_plot = df_plot.replace([float("inf"), float("-inf")], 0).fillna(0)
        # Transformar todas as colunas em INT (arredondando antes)
        df_plot = df_plot.round().astype(int)

        # Criar colunas de compra e venda
        df_plot["Compra"] = df_plot[df_plot > 0].sum(axis=1)
        df_plot["Venda"] = df_plot[df_plot < 0].sum(axis=1)

        # Aplicar formata√ß√£o para exibi√ß√£o
        st.table(df_plot.style.format("{:.0f}"))
        col_to_del = st.selectbox(
            "Coluna para apagar", st.session_state.df_total.columns, key="col_del")
        if st.button("Apagar coluna", key="btn_del_col"):
            st.session_state.df_total.drop(columns=[col_to_del], inplace=True)
            st.success(f"Coluna '{col_to_del}' removida.")

        def to_excel_bytes(df):
            buf = io.BytesIO()
            with pd.ExcelWriter(buf, engine="openpyxl") as writer:
                df.to_excel(writer, sheet_name="Posi√ß√µes")
            return buf.getvalue()
        st.download_button("Baixar Excel", data=to_excel_bytes(df_plot),
                           file_name="posicoes_por_fundo.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")


###############################################################################
# FUN√á√ïES DE P√ÅGINA ‚Äì AJUSTES PARA PASSAR CONTAGEM CARTEIRA
###############################################################################

def analisar_ativo(df: pd.DataFrame, df_div1: pd.DataFrame):
    st.header("Analisar Ativo")

    # NOVO ‚ûå ‚Äì junta a base principal com os ativos SEM FUNDO
    df_extras = st.session_state.get("df_extras", pd.DataFrame())
    df_full = pd.concat([df, df_extras], ignore_index=True).copy()

    # sele√ß√£o de ativo agora usa a lista ampliada
    ativo_sel = st.sidebar.selectbox(
        "Escolha o ativo:",
        sorted(df_full["Ativo"].unique())
    )

    # a partir daqui troque `df`  ‚Üí  `df_full`
    fundos_disponiveis = df_full[df_full["Ativo"]
                                 == ativo_sel]["Fundo"].unique().tolist()
    if len(fundos_disponiveis) > 1:
        usar_escolha = st.sidebar.checkbox("Escolher fundo-origem?")
        if usar_escolha:
            fundo_origem = st.sidebar.selectbox(
                "Fundo de origem:", fundos_disponiveis)
        else:
            fundo_origem = fundos_disponiveis[0]
        df_asset = df_full[(df_full["Ativo"] == ativo_sel) & (
            df_full["Fundo"] == fundo_origem)].copy()
    else:
        df_asset = df_full[df_full["Ativo"] == ativo_sel].copy()

    # Simulador de quantidade --------------------------------------------------
    qtd_atual = int(df_asset["Quantidade"].iloc[0])
    nova_qtd = st.sidebar.number_input(
        f"Nova quantidade (atual {qtd_atual})", value=qtd_atual, min_value=-100_000)
    if st.sidebar.button("Simular Quantidades Diferentes"):
        df_asset["Quantidade"] = nova_qtd
        df_asset["Juros projetados"] = df_asset["Fluxo descontado (R$)"] * \
            df_asset["Quantidade"]
        df_asset["DIV1_ATIVO"] = df_asset["Juros projetados"] * \
            0.0001 * (df_asset["Prazos (dias √∫teis)"] / 252)
        st.success("Nova quantidade aplicada!")

    # Filtro gen√©rico opcional -------------------------------------------------
    df_asset = filtro_generico(df_asset)

    # Verifica duplicidades (n√£o deve haver) -----------------------------------
    check_duplicates(df_asset, "Analisar Ativo")

    # Visualiza√ß√µes ------------------------------------------------------------
    plot_relacao_juros(df_asset)
    plot_div1_layout(df_asset, df_div1)

    if st.sidebar.checkbox("Mostrar base do ativo"):
        st.dataframe(df_asset)
        if "SEM FUNDO" in df_asset["Fundo"].unique():
            st.warning(
                "Ativos fora da carteira foram atualizados com as taxas do dia 25 de abril.")
        # Colocar checkbox para exportar base filtrada, mas trocando os pontos por v√≠rgulas
        if st.checkbox("Exportar base filtrada", key="chk_export"):
            df_asset_export = df_asset.copy()
            for col in ["Juros projetados", "Fluxo descontado (R$)", "Amortiza√ß√µes", "DIV1_ATIVO"]:
                df_asset_export[col] = df_asset_export[col].astype(float).apply(
                    lambda x: f"{x:,.2f}".replace(",", "").replace(".", ","))

            # Cria buffer de mem√≥ria
            output = io.BytesIO()

            # Salva o DataFrame no buffer como Excel usando openpyxl
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                df_asset_export.to_excel(
                    writer, index=False, sheet_name='Base')

            # Move o ponteiro para o in√≠cio do arquivo
            output.seek(0)

            # Bot√£o de download
            st.download_button(
                label="Baixar base filtrada",
                data=output,
                file_name=f"{ativo_sel}_base_filtrada.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            )


def analisar_fundo(df: pd.DataFrame, df_div1: pd.DataFrame):

    st.header("Analisar Fundo")
    lista = sorted(df["Fundo"].unique())
    #Tirar o fundo "AF DEB INCENTIVADAS"
    #lista.remove('AF DEB INCENTIVADAS')

    fundo_sel = st.sidebar.selectbox(
        "Selecione o fundo:", lista)
    df_fundo = df[df["Fundo"] == fundo_sel].copy()

    # ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî AVISO DE DIFEREN√áAS ‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî #
    # diffs = comparar_posicoes(fundo_sel, df_fundo["Ativo"].unique().tolist())
    # if diffs["faltando"]:
    #    st.warning(f"‚ùå Ativos presentes ontem mas AUSENTES hoje: {', '.join(diffs['faltando'])}")
    # if diffs["novos"]:
    #    st.info   (f"‚ûï Ativos NOVOS hoje (n√£o constavam ontem): {', '.join(diffs['novos'])}")

    # Filtro de ativos internos ------------------------------------------------
    ativos_fundo = sorted(df_fundo["Ativo"].unique())
    ativos_filt = st.sidebar.multiselect(
        "Filtrar ativos do fundo:", ativos_fundo, default=None)
    if not ativos_filt:
        ativos_filt2 = ativos_fundo
    else:
        ativos_filt2 = ativos_filt
    df_fundo = df_fundo[df_fundo["Ativo"].isin(ativos_filt2)]

    # Adicionar novos ativos ---------------------------------------------------
    novos_ativos = st.sidebar.checkbox("Adicionar novos ativos (tempor√°rio)")

    if novos_ativos:
        df_extras = st.session_state.get("df_extras", pd.DataFrame())
        base_cands = set(df["Ativo"])               # j√° existentes nos fundos
        extra_cands = set(df_extras["Ativo"])        # s√≥ no debentures2
        candidatos = sorted(
            list((base_cands | extra_cands) - set(df_fundo["Ativo"])))

        novos = st.sidebar.multiselect("Ativos a adicionar:", candidatos)

        for atv in novos:
            if atv in base_cands:                                   # l√≥gica antiga
                fundos_src = df[df["Ativo"] == atv]["Fundo"].unique().tolist()
                f_src = st.sidebar.selectbox(
                    f"Fundo origem {atv}", fundos_src, key=f"src_{atv}")
                dados = df[(df["Ativo"] == atv) & (
                    df["Fundo"] == f_src)].copy()

            else:                                                   # veio do df_extras
                dados = df_extras[df_extras["Ativo"] == atv].copy()
                # mant√©m default 100, mas o usu√°rio pode mudar depois
                dados["Juros projetados"] = dados["Fluxo descontado (R$)"] * \
                    dados["Quantidade"]
                dados["DIV1_ATIVO"] = (
                    dados["Juros projetados"] * 0.0001 *
                    (dados["Prazos (dias √∫teis)"] / 252)
                )

            # dados["Fundo"] = fundo_sel                    # destino final
            df_fundo = pd.concat([df_fundo, dados], ignore_index=True)

    # Simulador de quantidades -------------------------------------------------
    if ativos_filt:
        st.sidebar.markdown("### Simular novas quantidades")
        novas_qtds = {}
        for atv in sorted(df_fundo["Ativo"].unique()):
            q_atual = int(
                df_fundo.loc[df_fundo["Ativo"] == atv, "Quantidade"].iloc[0])
            novas_qtds[atv] = st.sidebar.number_input(
                atv, value=q_atual, key=f"num_{atv}")
        if st.sidebar.button("Aplicar quantidades", key="btn_qtd_fundo"):
            for a, q in novas_qtds.items():
                df_fundo.loc[df_fundo["Ativo"] == a, "Quantidade"] = q
            df_fundo["Juros projetados"] = df_fundo["Fluxo descontado (R$)"] * \
                df_fundo["Quantidade"]
            df_fundo["DIV1_ATIVO"] = df_fundo["Juros projetados"] * \
                0.0001 * (df_fundo["Prazos (dias √∫teis)"] / 252)
            st.success("Novas quantidades aplicadas!")

    else:
        if novos_ativos:
            st.sidebar.markdown("### Simular novas quantidades")
            novas_qtds = {}
            for atv in sorted(novos):
                q_atual = int(
                    df_fundo.loc[df_fundo["Ativo"] == atv, "Quantidade"].iloc[0])
                novas_qtds[atv] = st.sidebar.number_input(
                    atv, value=q_atual, key=f"num_{atv}")
            if st.sidebar.button("Aplicar quantidades", key="btn_qtd_fundo"):
                for a, q in novas_qtds.items():
                    df_fundo.loc[df_fundo["Ativo"] == a, "Quantidade"] = q
                df_fundo["Juros projetados"] = df_fundo["Fluxo descontado (R$)"] * \
                    df_fundo["Quantidade"]
                df_fundo["DIV1_ATIVO"] = df_fundo["Juros projetados"] * \
                    0.0001 * (df_fundo["Prazos (dias √∫teis)"] / 252)
                st.success("Novas quantidades aplicadas!")

    # Filtro gen√©rico opcional -------------------------------------------------
    df_fundo = filtro_generico(df_fundo)

    # Verifica duplicidades ----------------------------------------------------
    check_duplicates(df_fundo, "Analisar Fundo")

    # ‚ñ∫¬†Obt√©m quantidade de contratos j√° na carteira para esse fundo
    dap_by_fundo = st.session_state.get("dap_counts_by_fundo", pd.DataFrame())
    carteira_fundo = (
        dap_by_fundo[dap_by_fundo["Fundo"] == fundo_sel][["DAP", "Quantidade"]]
        .rename(columns={"Quantidade": "CARTEIRA"})
    )

    # Visualiza√ß√µes & contratos
    plot_relacao_juros(df_fundo)
    df_contr = plot_div1_layout(df_fundo, df_div1, carteira_fundo)
    atualizar_session_state_contratos(fundo_sel, df_contr)



def analisar_geral(df: pd.DataFrame, df_div1: pd.DataFrame):
    st.header("An√°lise Geral ‚Äì Consolidado de Fundos")

    # --- Sele√ß√£o m√∫ltipla de fundos (igual)
    todos_fundos = sorted(df["Fundo"].unique())
    fundos_sel = st.sidebar.multiselect(
        "Escolha os fundos:", todos_fundos, default=None)
    if not fundos_sel:
        fundos_sel = todos_fundos

    df_sel = df[df["Fundo"].isin(fundos_sel)].copy()

    # --- Sele√ß√£o opcional de ativos dentro desses fundos ----------------------
    ativos_disp = sorted(df_sel["Ativo"].unique())
    ativos_filtr = st.sidebar.multiselect(
        "Filtrar ativos dentro dos fundos selecionados:", ativos_disp, default=None)
    if not ativos_filtr:
        ativos_filtr = ativos_disp
    df_sel = df_sel[df_sel["Ativo"].isin(ativos_filtr)]

    # Filtro gen√©rico adicional (qualquer coluna) ------------------------------
    df_sel = filtro_generico(df_sel)

    # Checa duplicidades -------------------------------------------------------
    # check_duplicates(df_sel, "An√°lise Geral")

    # ‚Ä¶ (restante dos filtros)

    # ‚ñ∫¬†Quantos contratos j√° existem nestes fundos?
    dap_by_fundo = st.session_state.get("dap_counts_by_fundo", pd.DataFrame())
    carteira_geral = (
        dap_by_fundo[dap_by_fundo["Fundo"].isin(fundos_sel)]
        .groupby("DAP", as_index=False)["Quantidade"].sum()
        .rename(columns={"Quantidade": "CARTEIRA"})
    )

    # Visualiza√ß√µes
    plot_relacao_juros(df_sel)
    plot_div1_layout(df_sel, df_div1, carteira_geral)

    if st.sidebar.checkbox("Mostrar base consolidada"):
        st.dataframe(df_sel)
        # Colocar um aviso de os ativos fora da cartera foram atualizados com as taxas do dia 27 de novembro
        if "SEM FUNDO" in df_sel["Fundo"].unique():
            st.warning(
                "Ativos fora da carteira foram atualizados com as taxas do dia 27 de novembro.")


def analisar_spreads() -> None:
    """
    Parte de spreads NTNB √ó DAP ‚Äì filtros, linha Plotly, barras Plotly.
    """
    st.subheader("An√°lise ‚Äì Spreads NTNB √ó DAP")

    # ‚ñ∏ carrega uma vez -----------------------------------------------------
    if "df_spread_melt" not in st.session_state:
        df_melt_tmp, df_vert_tmp = _prep_spread_df("Dados/BBG - ECO DASH_te.xlsx")
        st.session_state["df_spread_melt"] = df_melt_tmp
        st.session_state["df_spread_vert"] = df_vert_tmp

    df_melt_full = st.session_state["df_spread_melt"]
    df_vert_full = st.session_state["df_spread_vert"]

    # ‚ñ∏ sidebar ‚Äì filtros comuns ------------------------------------------
    with st.sidebar:
        st.write('---')
        st.markdown("## Filtros ‚Äì Spreads")
        st.markdown("#### Spread vs. Data")

        min_date = df_melt_full["DATA"].min().date()
        max_date = df_melt_full["DATA"].max().date()

        col_a, col_b = st.columns(2)
        start_date = col_a.date_input("In√≠cio", min_value=min_date,
                                      max_value=max_date, value=min_date,
                                      key="hs_start")
        end_date = col_b.date_input("Fim",    min_value=min_date,
                                    max_value=max_date, value=max_date,
                                    key="hs_end")

        freq_map = {"Di√°ria": "D", "Semanal": "W", "Mensal": "M"}
        freq = st.selectbox("Frequ√™ncia", list(freq_map), 0)

    if start_date > end_date:
        st.warning("A data inicial √© posterior √† final ‚Äì ajuste o intervalo.")
        return

    # ‚ñ∏ aplica per√≠odo & reamostra -----------------------------------------
    mask = df_melt_full["DATA"].dt.date.between(start_date, end_date)
    df_melt = df_melt_full[mask].copy()
    df_vert = df_vert_full[df_vert_full["DATA"].dt.date
                           .between(start_date, end_date)].copy()

    if freq != "Di√°ria":
        rule = freq_map[freq]                       # "W" ou "M"
        # ‚Äì df_melt
        wide = (df_melt.pivot(index="DATA", columns="Tipo", values="Spread")
                .resample(rule, label="right", closed="right")
                .median()
                .dropna(how="all"))
        df_melt = (wide.stack().rename("Spread").reset_index())
        df_melt["Data_Str"] = df_melt["DATA"].dt.strftime("%Y-%m-%d")
        color_map = (df_melt_full.drop_duplicates("Tipo")
                     .set_index("Tipo")["Color"])
        df_melt["Color"] = df_melt["Tipo"].map(color_map)
        # ‚Äì df_vert
        wide_v = (df_vert.pivot(index="DATA", columns="Vertice", values="Spread")
                  .resample(rule, label="right", closed="right")
                  .median()
                  .dropna(how="all"))
        df_vert = (wide_v.stack().rename("Spread").reset_index()
                   .assign(Vertice=lambda x: x["Vertice"].astype(int)))

    # ‚ïê‚ïê‚ïê‚ïê‚ïê 1) LINHA (Plotly) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    pares = sorted(df_melt["Tipo"].unique())
    media_lbl = "M√©dia dos Spreads"
    opcoes = [media_lbl] + pares

    selecionados = st.sidebar.multiselect(
        "V√©rtices para a linha", opcoes, default=[media_lbl])

    # monta DataFrame com m√©dias + pares escolhidos
    dfs = []
    if media_lbl in selecionados:
        df_media = (df_melt[df_melt["Tipo"] != "Spread B25/DAP25"]
                    .groupby("DATA", as_index=False)["Spread"].mean()
                    .assign(Tipo=media_lbl, Color="#000000"))
        df_media["Data_Str"] = df_media["DATA"].dt.strftime("%Y-%m-%d")
        dfs.append(df_media)

    for par in selecionados:
        if par != media_lbl:
            dfs.append(df_melt[df_melt["Tipo"] == par])

    df_plot = pd.concat(dfs, ignore_index=True)

    fig_line = go.Figure()
    for tipo, grp in df_plot.groupby("Tipo"):
        pontos = len(grp)
        text = ['' if i % 5 else f'{v:.2f}' for i, v in enumerate(grp["Spread"])] \
            if len(selecionados) == 1 else None
        modo = "lines+markers+text" if text else "lines+markers"

        fig_line.add_trace(go.Scatter(
            x=grp["Data_Str"], y=grp["Spread"],
            mode=modo, text=text, textposition="top center",
            marker=dict(color=grp["Color"].iloc[0], size=6),
            name=tipo))

    fig_line.update_layout(
        title="Spreads NTNB √ó DAP ‚Äì evolu√ß√£o temporal",
        xaxis_title="Data", yaxis_title="Spread (p.p.)",
        plot_bgcolor="white", height=450, legend_title_text="")

    st.plotly_chart(fig_line, use_container_width=True)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê 2) BARRAS (Plotly) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    with st.sidebar:
        st.write('---')
        st.markdown("#### Spread √ó V√©rtice")

        agg_opt = st.radio(
            "Base de c√°lculo",
            ["Di√°rio", "Mediana Semanal", "Mediana Mensal"],
            0, key="hs_bar_agg")

    ordem = ["25", "26", "27", "28", "30", "32", "35", "40"]
    df_base = df_vert_full.copy()

    if agg_opt != "Di√°rio":
        rule = "W" if agg_opt == "Mediana Semanal" else "M"
        df_base = (df_base.pivot(index="DATA", columns="Vertice", values="Spread")
                   .resample(rule, label="right", closed="right")
                   .median()
                   .stack()
                   .rename("Spread")
                   .reset_index())

    datas_disp = sorted(df_base["DATA"].dt.date.unique())

    with st.sidebar:
        if agg_opt == "Di√°rio":
            data_ref = st.date_input("Data de refer√™ncia",
                                     value=datas_disp[-1],
                                     min_value=datas_disp[0],
                                     max_value=datas_disp[-1],
                                     key="hs_bar_refdate")
        else:
            rotulo = "Semana" if agg_opt == "Mediana Semanal" else "M√™s"
            data_ref = st.selectbox(f"{rotulo} de refer√™ncia",
                                    datas_disp,
                                    index=len(datas_disp) - 1,
                                    key="hs_bar_refsel")

    df_sel = df_base[df_base["DATA"].dt.date == data_ref]
    spread_map = dict(zip(df_sel["Vertice"].astype(str), df_sel["Spread"]))
    y_vals = [spread_map.get(v, None) for v in ordem]
    text_vals = [f"{v:.2f}" if v is not None else "" for v in y_vals]

    fig_bar = go.Figure(go.Bar(
        x=ordem, y=y_vals,
        text=text_vals, textposition="outside",
        marker_color="#1F4E79"))

    fig_bar.update_layout(
        title=f"Spreads por V√©rtice ‚Äì {data_ref:%d/%m/%Y}",
        xaxis=dict(title="V√©rtice (anos)", type="category"),
        yaxis=dict(title="Spread (p.p.)"),
        plot_bgcolor="white", height=550, showlegend=False)

    st.plotly_chart(fig_bar, use_container_width=True)


# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


def analisar_spreads_deb_b(df_posicao: pd.DataFrame) -> None:
    """
    ‚Ä¢ Gr√°fico¬†1¬†‚Äì Spread por ativo (linha)                    ‚Äì opcional
    ‚Ä¢ Gr√°fico¬†2¬†‚Äì Spread m√©dio ponderado por v√©rtice/fundo    ‚Äì opcional
    ‚Ä¢ Gr√°fico¬†3¬†‚Äì S√©rie temporal do spread m√©dio ponderado    ‚Äì 1‚ÄëN fundos
    """
    st.header("Spreads Deb√™ntures √ó NTNB‚ÄëB")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê 0.¬†CARREGAS B√ÅSICAS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    tx_hist = (
        pd.read_csv("Dados/dados_ativos (01_01_2025-29_04_2025).csv")
          .rename(columns={"position_date": "DATA",
                           "ativo": "Ativo",
                           "tax": "TAX_INDIC"})
    )
    tx_hist["Ativo"] = tx_hist["Ativo"].str.upper().str.strip()
    tx_hist["DATA"] = pd.to_datetime(tx_hist["DATA"], errors="coerce")
    tx_hist["TAX_INDIC"] = pd.to_numeric(tx_hist["TAX_INDIC"], errors="coerce")
    tx_hist.dropna(subset=["DATA", "TAX_INDIC"], inplace=True)

    if "df_spreads_af" not in st.session_state:
        st.session_state["df_spreads_af"] = load_spreads_afinvest()
    lk = st.session_state["df_spreads_af"]

    if "df_ntnb_long" not in st.session_state:
        st.session_state["df_ntnb_long"] = _prep_ntnb_df(
            "BBG - ECO DASH_te.xlsx")

    # st.write(st.session_state["df_ntnb_long"])

    nt_long = st.session_state["df_ntnb_long"].copy()
    nt_long["DATA"] = pd.to_datetime(nt_long["DATA"], errors="coerce")
    nt_long["NTNB_YIELD"] = pd.to_numeric(
        nt_long["NTNB_YIELD"], errors="coerce")
    nt_long.dropna(subset=["DATA", "NTNB_YIELD"], inplace=True)

    vertices_disp = sorted(nt_long["B_REF"].unique())

    # ‚ïê‚ïê‚ïê‚ïê‚ïê 1.¬†BASE¬†GERAL COM SPREAD (para reutilizar) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    base0 = (
        df_posicao[["Ativo", "Fundo", "DIV1_ATIVO"]]
        .merge(lk, on="Ativo", how="left")
        .merge(tx_hist, on="Ativo", how="left")
        .dropna(subset=["B_REF", "DATA", "TAX_INDIC"])
    )

    # merge_asof por v√©rtice
    frames = []
    for b, left in base0.groupby("B_REF", sort=True):
        right = nt_long[nt_long["B_REF"] == b][[
            "DATA", "NTNB_YIELD"]].sort_values("DATA")
        joined = pd.merge_asof(left.sort_values("DATA"), right,
                               on="DATA", direction="backward")
        frames.append(joined)
    base = (pd.concat(frames, ignore_index=True)
              .dropna(subset=["NTNB_YIELD"]))

    base["SPREAD_PP"] = ((1+(base["TAX_INDIC"]/100)) /
                         (1+(base["NTNB_YIELD"]/100))) - 1
    base["SPREAD_PP"] = base["SPREAD_PP"] * 100
    base["DATA_DATE"] = base["DATA"].dt.date  # col. auxiliar p/ compara√ß√µes

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helpers_spreads.py ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ


@st.cache_data(show_spinner=False, ttl=4*3600)   # 4 h
def get_df_spread_ready(
        df_posicao: pd.DataFrame,
        df_extras:  pd.DataFrame,
        df_tx_hist: pd.DataFrame,
        df_ntnb:    pd.DataFrame,
        df_lookup:  pd.DataFrame
) -> pd.DataFrame:
    
    """
    Constr√≥i a base completa para todos os gr√°ficos de *Spreads Deb-B*.

    Retorna um DataFrame j√° pronto, contendo **apenas dias-√∫teis** e com as
    colunas-chave:

        DATA (datetime) ‚Ä¢ DATA_DATE (date) ‚Ä¢ Fundo ‚Ä¢ B_REF  
        TAX_INDIC ‚Ä¢ NTNB_YIELD ‚Ä¢ SPREAD_PP ‚Ä¢ DIV1_ATIVO

    Premissas novas
    --------------- 
    1. `df_posicao` **j√°** traz DIV1_ATIVO di√°rio (c√°lculo feito na carga do
       parquet; ver `load_carteira_recent` revisto).  
    2. `df_tx_hist` tem as curvas dos ativos  
       (Ativo ‚Ä¢ DATA ‚Ä¢ TAX_INDIC).  
    3. `df_ntnb` √© a curva longa das NTNBs  
       (DATA ‚Ä¢ B_REF ‚Ä¢ NTNB_YIELD).  
    4. `df_lookup` faz o mapeamento *Ativo ‚Üí B_REF*.
    """

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 1) posi√ß√£o + extras  ‚Üí normaliza & garante datetime
    # --------------------------------------------------------------------
    # ‚îÄ‚îÄ 1) posi√ß√£o + extras ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    df_pos = pd.concat([df_posicao, df_extras], ignore_index=True).copy()
    df_pos.rename(columns={"Data": "DATA_POS"},
                  inplace=True)          # ‚Üê rename
    df_pos["DATA_POS"] = pd.to_datetime(df_pos["DATA_POS"], errors="coerce")
    df_pos["Ativo_up"] = df_pos["Ativo"].str.upper().str.strip()

    # ‚îÄ‚îÄ 2) lookup B_REF ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    lk = df_lookup.copy()
    lk["Ativo_up"] = lk["Ativo"].str.upper().str.strip()

    # ‚îÄ‚îÄ 3) hist√≥rico de taxas ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    tx = df_tx_hist.copy()
    tx.rename(columns={"DATA": "DATA_HIST"},
              inplace=True)             # ‚Üê rename
    tx["DATA_HIST"] = pd.to_datetime(tx["DATA_HIST"], errors="coerce")

    # ‚îÄ‚îÄ 4) junta tudo (posi√ß√£o √ó lookup √ó taxas) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    base0 = (
        df_pos[["Ativo_up", "Fundo", "DIV1_ATIVO", "DATA_POS"]]
        .merge(lk[["Ativo_up", "B_REF"]], on="Ativo_up", how="left")
        .merge(tx[["Ativo", "DATA_HIST", "TAX_INDIC"]],
               left_on="Ativo_up", right_on="Ativo", how="left")
        .dropna(subset=["B_REF", "DATA_HIST", "TAX_INDIC"])
    )

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 4) para cada v√©rtice faz merge_asof com o yield da NTNB correspondente
    #    (toler√¢ncia ¬±30 dias, pega o preg√£o mais pr√≥ximo <= DATA)
    # --------------------------------------------------------------------
    # ‚îÄ‚îÄ 5) merge_asof com NTNB ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    bases = []
    for b_ref, grp in base0.groupby("B_REF", sort=True):
        ntb_ref = df_ntnb.loc[df_ntnb["B_REF"]
                              == b_ref, ["DATA", "NTNB_YIELD"]]
        joined = pd.merge_asof(
            grp.sort_values("DATA_HIST"),
            ntb_ref.sort_values("DATA"),
            left_on="DATA_HIST", right_on="DATA",
            direction="nearest",
            tolerance=pd.Timedelta(days=30)
        )
        bases.append(joined)

    base = pd.concat(bases, ignore_index=True).dropna(subset=["NTNB_YIELD"])

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 5) calcula spread, auxiliares e filtra fins-de-semana
    # --------------------------------------------------------------------
    base["SPREAD_PP"] = ((1 + (base["TAX_INDIC"]/100)) /
                         (1 + (base["NTNB_YIELD"]/100))) - 1
    base["SPREAD_PP"] = base["SPREAD_PP"] * 100
    base["DATA_DATE"] = base["DATA_HIST"].dt.date
    base = base[base["DATA_HIST"].dt.dayofweek < 5]     # 0=seg ‚Ä¶ 4=sex

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    # 6) ordena / devolve
    # --------------------------------------------------------------------
    cols_core = [
        "DATA", "DATA_DATE", "Fundo", "Ativo_up", "B_REF",
        "TAX_INDIC", "NTNB_YIELD", "SPREAD_PP", "DIV1_ATIVO"
    ]
    outras = [c for c in base.columns if c not in cols_core]
    return base[cols_core + outras]

# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ p√°ginas / an√°lise Spreads Deb-B ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def analisar_spreads_deb_b2(_: pd.DataFrame) -> None:
    """Usa df pronto em cache (n√£o importa par√¢metro enviado)."""

    # 1. dataframe pr√©-processado --------------------------------------------
    with st.spinner("Carregando dados..."):
        df_ready = get_df_spread_ready(
            st.session_state["df_carteira_recent"],
            st.session_state.get("df_extras", pd.DataFrame()),
            _load_tx_hist(),              # fun√ß√µes r√°pidas de leitura CSV
            _load_ntnb_long(),
            _load_lookup_spreads()
        )

    # 2. mini-gr√°ficos -------------------------------------------------------
    def grafico_ativos(df: pd.DataFrame) -> None:
        st.subheader("Gr√°fico 1 ‚Äì Spread por Ativo")
        ativos_disp = sorted(df["Ativo_up"].unique())
        sel = st.sidebar.multiselect(
            "Ativos a exibir:", ativos_disp, ativos_disp[:1])
        if not sel:
            st.info("Selecione ao menos um ativo.")
            return

        dfp = df.query("Ativo_up in @sel").copy()
        fig = go.Figure()
        for atv, g in dfp.groupby("Ativo_up"):
            fig.add_trace(go.Scatter(x=g["DATA"], y=g["SPREAD_PP"],
                                     mode="lines+markers",
                                     name=f"{atv} (B {g['B_REF'].iloc[0]})"))
        fig.update_layout(height=460, plot_bgcolor="white",
                          xaxis_title="Data", yaxis_title="Spread (p.p.)",
                          title="Evolu√ß√£o di√°ria do spread (Ativo √ó B-ref)")
        st.plotly_chart(fig, use_container_width=True)

        # ‚ñº tabela opcional ----------------------------------------------------
        if st.checkbox("Mostrar dados do gr√°fico (Ativos)"):
            cols_show = ["DATA", "Ativo_up", "B_REF",
                         "TAX_INDIC", "NTNB_YIELD", "SPREAD_PP"]

            df_tbl = (
                dfp[cols_show]
                .drop_duplicates(subset=["Ativo_up", "DATA", "B_REF"])
                .rename(columns={"Ativo_up": "Ativo"})
                .assign(DATA=lambda d: d["DATA"].dt.strftime("%Y-%m-%d"))
                # √≠ndice √∫nico (MultiIndex)
                .set_index(["DATA", "Ativo"])
                .sort_index()
            )
            sty = (df_tbl.style
                   .format({                       # casas decimais
                       "SPREAD_PP": "{:.2f}",
                       "TAX_INDIC": "{:.4f}",
                       "NTNB_YIELD": "{:.4f}"
                   })
                   # ‚Äï visual ‚Äï
                   .set_table_styles([
                       {"selector": "thead th",
                        "props": [("background", "#1F4E79"),
                                  ("color", "white"),
                                  ("font-weight", "bold")]},
                       {"selector": "tbody tr:nth-child(even)",
                        "props": [("background", "#F2F2F2")]},
                       {"selector": "tbody tr:hover",
                        "props": [("background", "#D6EAF8")]}
                   ])
                   .set_properties(**{
                       "border":       "1px solid #DDD",
                       "text-align":   "right",
                       "white-space":  "nowrap"})
                   )

            st.table(sty)      # usa Styler ‚áí cabe√ßalhos fixos + formata√ß√£o
            buffer = io.BytesIO()
            with pd.ExcelWriter(buffer, engine="openpyxl") as writer:
                df_tbl.to_excel(writer, sheet_name="Spreads_Ativos")

            st.download_button(
                label="üì• Baixar tabela em Excel",
                data=buffer.getvalue(),
                file_name="spreads_ativos.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    

    def grafico_vertices_fundo(df: pd.DataFrame) -> None:
        st.subheader("Gr√°fico 2 ‚Äì Spread do Fundo por V√©rtice")

        fundos = sorted(df["Fundo"].unique())
        st.sidebar.write('---')
        fundo = st.sidebar.selectbox("Fundo:", fundos)

        # datas dispon√≠veis para o fundo
        datas_fundo = sorted(df.query("Fundo == @fundo")["DATA_DATE"].unique())
        if not datas_fundo:
            st.info("Fundo sem dados.")
            return

        # controles de data-ref
        col1, col2 = st.sidebar.columns(2)
        data_ref = col1.date_input("Data-ref 1:", value=datas_fundo[-1],
                                   min_value=datas_fundo[0], max_value=datas_fundo[-1])
        # comparar = col1.checkbox("Comparar com outra data?", value=True)
        comparar = True
        if not comparar:
            data_ref2 = None
        else:
            data_ref2 = col2.date_input("Data-ref 2:", value=datas_fundo[0],
                                        min_value=datas_fundo[0], max_value=datas_fundo[-1])
        spread_tipo = st.sidebar.radio("Tipo de m√©dia:",
                                       ("Ponderada", "Simples"), horizontal=True)

        # ----------  fun√ß√£o que monta gr√°fico + tabela p/ uma data  -------------
        def _build_vert(dt):
            df_ref = df.query("Fundo == @fundo & DATA_DATE == @dt").copy()
            if df_ref.empty:
                return None, None

            if spread_tipo == "Ponderada":
                medias = (df_ref.groupby("B_REF")
                          .apply(lambda g: np.average(g["TAX_INDIC"],
                                                      weights=g["DIV1_ATIVO"]))
                          .reset_index(name="TAX_MED"))
            else:  # m√©dia simples
                medias = (df_ref.groupby("B_REF", as_index=False)["TAX_INDIC"]
                          .mean().rename(columns={"TAX_INDIC": "TAX_MED"}))

            ntb = (_load_ntnb_for_date(dt)
                   .rename(columns={"NTNB_YIELD": "NTNB"}))
            df_vert = medias.merge(ntb, on="B_REF", how="left")
            df_vert["SPREAD_PP"] = df_vert["TAX_MED"] - df_vert["NTNB"]

            # gr√°fico
            tit = "ponderado" if spread_tipo == "Ponderada" else "m√©dio simples"
            fig = go.Figure(go.Bar(
                x=df_vert["B_REF"], y=df_vert["SPREAD_PP"],
                text=[f"{v:.2f}" if pd.notna(
                    v) else "" for v in df_vert["SPREAD_PP"]],
                textposition="outside", marker_color="#1F4E79"))
            fig.update_layout(height=520, plot_bgcolor="white",
                              title=f"{fundo} ‚Äì Spread {tit} ({dt})",
                              xaxis_title="V√©rtice (B)",
                              yaxis_title="Spread (p.p.)")

            # tabela formatada
            tbl = (df_vert.set_index("B_REF").drop(columns=["DATA"], axis=1)
                          .style.format({"TAX_MED": "{:.4f}",
                                         "NTNB": "{:.4f}",
                                         "SPREAD_PP": "{:.2f}"}))
            return fig, tbl

        # ----------  render  -----------------------------------------------------
        if comparar and data_ref2:
            col_esq, col_meio, col_dir = st.columns([4.9, 0.2, 4.9])

            fig1, tbl1 = _build_vert(data_ref)
            fig2, tbl2 = _build_vert(data_ref2)

            with col_esq:
                if fig1:
                    st.plotly_chart(fig1, use_container_width=True)
                st.table(tbl1)

            with col_meio:
                st.markdown("<div style='border-left:2px solid #ccc;height:80vh;'></div>",
                            unsafe_allow_html=True)

            with col_dir:
                if fig2:
                    st.plotly_chart(fig2, use_container_width=True)
                st.table(tbl2)

        else:
            fig, tbl = _build_vert(data_ref)
            st.plotly_chart(fig, use_container_width=True)
            if tbl and st.checkbox("Mostrar tabela", key="tbl_single"):
                st.table(tbl)

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ mini-gr√°fico 3 ‚Äì s√©rie temporal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    def grafico_serie_fundos(df: pd.DataFrame) -> None:
        st.subheader("Gr√°fico 3 ‚Äì S√©rie temporal do Spread m√©dio (ponderado)")
        fundos = sorted(df["Fundo"].unique())
        st.sidebar.write('---')
        sel = st.sidebar.multiselect("Fundos:", fundos, fundos[:2])
        if not sel:
            st.info("Selecione ao menos um fundo.")
            return

        fig = go.Figure()
        for f in sel:
            def _m_pond(g):
                w = g["DIV1_ATIVO"].values
                return (np.average(g["SPREAD_PP"], weights=w)
                        if w.sum() else g["SPREAD_PP"].mean())

            serie = (df.query("Fundo == @f")
                       .groupby("DATA_DATE")
                       .apply(_m_pond)
                       .rename("SPREAD")
                       .reset_index())

            fig.add_trace(go.Scatter(x=serie["DATA_DATE"], y=serie["SPREAD"],
                                     mode="lines+markers", name=f))

        fig.update_layout(height=460, plot_bgcolor="white",
                          xaxis_title="Data", yaxis_title="Spread (p.p.)",
                          title="Spread m√©dio ponderado ‚Äì evolu√ß√£o por Fundo")
        st.plotly_chart(fig, use_container_width=True)

    # 3. layout em tabs -------------------------------------------------------
    tab1, tab2, tab3 = st.tabs(["Ativos", "V√©rtice/Fundo", "S√©rie Fundos"])
    with tab1:
        grafico_ativos(df_ready)
    with tab2:
        grafico_vertices_fundo(df_ready)
    with tab3:
        grafico_serie_fundos(df_ready)
    if st.checkbox("DEBUG ‚Äì ver DIV1 zeros"):
        z = st.session_state["df_carteira_recent"]
        st.write(z[z["DIV1_ATIVO"] == 0].head())


def _load_tx_hist():
    return (pd.read_csv("Dados/dados_ativos (01_01_2025-29_04_2025).csv")
              .rename(columns={"position_date": "DATA", "ativo": "Ativo",
                               "tax": "TAX_INDIC"})
              .assign(Ativo=lambda d: d["Ativo"].str.upper().str.strip(),
                      DATA=lambda d: pd.to_datetime(
                          d["DATA"], errors="coerce"),
                      TAX_INDIC=lambda d:
                          pd.to_numeric(d["TAX_INDIC"], errors="coerce"))
              .dropna(subset=["DATA", "TAX_INDIC"]))


@st.cache_data
def _load_ntnb_long():
    return _prep_ntnb_df("Dados/BBG - ECO DASH_te.xlsx")


def _load_ntnb_for_date(d):
    nt = _load_ntnb_long()
    return (nt[nt["DATA"].dt.date <= d]
            .sort_values(["B_REF", "DATA"])
            .groupby("B_REF").tail(1))


@st.cache_data
def _load_lookup_spreads():
    lk = load_spreads_afinvest()
    lk["Ativo"] = lk["Ativo"].str.upper().str.strip()
    return lk


# ‚ïê‚ïê‚ïê‚ïê‚ïê 2.¬†GR√ÅFICO¬†1¬†‚Äì ATIVOS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
def analisar_spreads_deb_b(df_posicao: pd.DataFrame) -> None:
    """
    ‚Ä¢ Gr√°fico¬†1¬†‚Äì Spread por ativo (linha)                    ‚Äì opcional
    ‚Ä¢ Gr√°fico¬†2¬†‚Äì Spread m√©dio ponderado por v√©rtice/fundo    ‚Äì opcional
    ‚Ä¢ Gr√°fico¬†3¬†‚Äì S√©rie temporal do spread m√©dio ponderado    ‚Äì 1‚ÄëN fundos
    """
    st.header("Spreads Deb√™ntures √ó NTNB‚ÄëB")
    # NOVO ‚ûå ‚Äì junta a base principal com os ativos SEM FUNDO
    df_extras = st.session_state.get("df_extras", pd.DataFrame())
    df_posicao = pd.concat([df_posicao, df_extras], ignore_index=True).copy()

    def _spread_fundo_dia(df_dia: pd.DataFrame) -> float:
        # ‚ë† m√©dia ponderada da TAX_INDIC em cada v√©rtice
        verts = (df_dia.groupby("B_REF")
                       .apply(lambda g: pd.Series({
                           "DIV1_SUM":  g["DIV1_ATIVO"].sum(),
                           "TAX_POND":  np.average(g["TAX_INDIC"],
                                                   weights=g["DIV1_ATIVO"])
                       }))
                 .reset_index())

        # ‚ë° NTNB mais recente ‚â§ data‚Äëref
        data_ref = df_dia["DATA_DATE"].iloc[0]
        ntb_ref = (nt_long[nt_long["DATA"].dt.date <= data_ref]
                   .sort_values(["B_REF", "DATA"])
                   .groupby("B_REF").tail(1)[["B_REF", "NTNB_YIELD"]])
        verts = verts.merge(ntb_ref, on="B_REF", how="left")
        verts["SPREAD_VERT"] = verts["TAX_POND"] - verts["NTNB_YIELD"]

        # ‚ë¢ resultado ponderado pelos DIV1_SUM de cada v√©rtice
        num = (verts["SPREAD_VERT"] * verts["DIV1_SUM"]).sum()
        den = verts["DIV1_SUM"].sum()
        return num / den if den else np.nan
    # ----------------------------------------------------------------

    # ‚ïê‚ïê‚ïê‚ïê‚ïê 0.¬†CARREGAS B√ÅSICAS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    tx_hist = (
        pd.read_csv("Dados/dados_ativos (01_01_2025-29_04_2025).csv")
          .rename(columns={"position_date": "DATA",
                           "ativo": "Ativo",
                           "tax": "TAX_INDIC"})
    )
    tx_hist["Ativo"] = tx_hist["Ativo"].str.upper().str.strip()
    tx_hist["DATA"] = pd.to_datetime(tx_hist["DATA"], errors="coerce")
    tx_hist["TAX_INDIC"] = pd.to_numeric(tx_hist["TAX_INDIC"], errors="coerce")
    tx_hist.dropna(subset=["DATA", "TAX_INDIC"], inplace=True)

    if "df_spreads_af" not in st.session_state:
        st.session_state["df_spreads_af"] = load_spreads_afinvest()
    lk = st.session_state["df_spreads_af"]

    if "df_ntnb_long" not in st.session_state:
        st.session_state["df_ntnb_long"] = _prep_ntnb_df(
            "BBG - ECO DASH_te.xlsx")

    # st.write(st.session_state["df_ntnb_long"])

    nt_long = st.session_state["df_ntnb_long"].copy()
    nt_long["DATA"] = pd.to_datetime(nt_long["DATA"], errors="coerce")
    nt_long["NTNB_YIELD"] = pd.to_numeric(
        nt_long["NTNB_YIELD"], errors="coerce")
    nt_long.dropna(subset=["DATA", "NTNB_YIELD"], inplace=True)

    vertices_disp = sorted(nt_long["B_REF"].unique())

    # ‚ïê‚ïê‚ïê‚ïê‚ïê 1.¬†BASE¬†GERAL COM SPREAD (para reutilizar) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # ################################## PRECISO ADICIONAR UMA FORMA DE ANALISAR DUPLICIDADES COMO √â FEITO NAS OUTRAS TELAS

    base0 = (
        df_posicao[["Ativo", "Fundo", "DIV1_ATIVO"]]
        .merge(lk, on="Ativo", how="left")
        .merge(tx_hist, on="Ativo", how="left")
        .dropna(subset=["B_REF", "DATA", "TAX_INDIC"])
    )

    # merge_asof por v√©rtice
    frames = []
    for b, left in base0.groupby("B_REF", sort=True):
        right = nt_long[nt_long["B_REF"] == b][[
            "DATA", "NTNB_YIELD"]].sort_values("DATA")
        joined = pd.merge_asof(left.sort_values("DATA"), right,
                               on="DATA", direction="backward")
        frames.append(joined)
    base = (pd.concat(frames, ignore_index=True)
              .dropna(subset=["NTNB_YIELD"]))

    base["SPREAD_PP"] = base["TAX_INDIC"] - base["NTNB_YIELD"]
    base["DATA_DATE"] = base["DATA"].dt.date  # col. auxiliar p/ compara√ß√µes

    # ======================================================================
    # CONTROLES GERAIS DE VISUALIZA√á√ÉO
    # ======================================================================
    st.sidebar.markdown("### O que exibir?")
    show_g1 = st.sidebar.checkbox("Gr√°fico‚ÄØ1 ‚Äì Ativos", value=True)
    show_g2 = st.sidebar.checkbox("Gr√°fico‚ÄØ2 ‚Äì V√©rtices do fundo", value=True)
    show_g3 = st.sidebar.checkbox("Gr√°fico‚ÄØ3 ‚Äì S√©rie por fundo(s)", value=True)

    # Lista de fundos dispon√≠vel ‚Äì usada nos dois √∫ltimos gr√°ficos
    fundos_disp = sorted(base["Fundo"].unique())

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 1.¬†GR√ÅFICO‚ÄØ1 ‚Äì SPREAD POR ATIVO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if show_g1:
        st.subheader("Gr√°fico‚ÄØ1¬†‚Äì Spread por Ativo")
        ativos_disp = sorted(base["Ativo"].unique())
        ativos_sel = st.sidebar.multiselect("Ativos:", ativos_disp,
                                            default=ativos_disp[:1])

        df_plot = (base[base["Ativo"].isin(ativos_sel)]
                   .assign(Data_Str=lambda x: x["DATA"].dt.strftime("%Y‚Äë%m‚Äë%d")))

        # col_g1, col_tbl1 = st.columns([3, 2])
        # with col_g1:
        fig = go.Figure()
        for atv, grp in df_plot.groupby("Ativo"):
            grp = grp.sort_values("DATA")
            fig.add_trace(go.Scatter(
                x=grp["Data_Str"], y=grp["SPREAD_PP"],
                mode="lines+markers",
                name=f"{atv} (B {grp['B_REF'].iloc[0]})"))
        fig.update_layout(height=520, plot_bgcolor="white",
                          xaxis_title="Data", yaxis_title="Spread (p.p.)")
        st.plotly_chart(fig, use_container_width=True)

        # with col_tbl1:
        #    st.dataframe(df_plot[["DATA","Ativo","B_REF","SPREAD_PP"]]
        #                 .sort_values("DATA")
        #                 .style.format({"SPREAD_PP":"{:.2f}"}))

        # Checkbox para mostrar tabela com os dados do gr√°fico
        if st.checkbox("Mostrar tabela com dados do gr√°fico", key="chk_g1_data"):
            st.dataframe(df_plot)
            st.dataframe(
                df_plot[["DATA", "Ativo", "B_REF", "SPREAD_PP"]]
                .drop_duplicates()
                .sort_values("DATA")
                .style.format({"SPREAD_PP": "{:.2f}"})   # ‚Üê corrigido
            )

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 2.¬†GR√ÅFICO‚ÄØ2 ‚Äì V√âRTICE / FUNDO ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if show_g2:
        st.subheader("Gr√°fico‚ÄØ2¬†‚Äì Spread m√©dio ponderado por v√©rtice")

        fundo_sel = st.sidebar.selectbox("Fundo (para o¬†Gr√°fico‚ÄØ2):",
                                         fundos_disp)
        datas_fundo = sorted(
            base[base["Fundo"] == fundo_sel]["DATA_DATE"].unique())
        data_ref = st.sidebar.date_input("Data‚Äëref:",
                                         value=datas_fundo[-1],
                                         min_value=datas_fundo[0],
                                         max_value=datas_fundo[-1])

        df_ref = base[(base["Fundo"] == fundo_sel) &
                      (base["DATA_DATE"] == data_ref)].copy()
        if df_ref.empty:
            st.info("Fundo sem ativos nessa data.")
        else:
            medias = (df_ref.groupby("B_REF")
                      .apply(lambda g: np.average(g["TAX_INDIC"],
                                                  weights=g["DIV1_ATIVO"]))
                      .reset_index(name="TAX_POND"))
            pesos = df_ref.groupby("B_REF")["DIV1_ATIVO"].sum().reset_index()
            ntb_lookup = (nt_long[nt_long["DATA"].dt.date <= data_ref]
                          .sort_values(["B_REF", "DATA"])
                          .groupby("B_REF").tail(1)
                          .loc[:, ["B_REF", "NTNB_YIELD"]])

            df_vert = (medias.merge(ntb_lookup, on="B_REF", how="left")
                       .merge(pesos, on="B_REF", how="left"))
            df_vert["SPREAD_PP"] = df_vert["TAX_POND"] - df_vert["NTNB_YIELD"]

            col_g2, col_tbl2 = st.columns([5, 5])
            with col_g2:
                fig2 = go.Figure(go.Bar(
                    x=df_vert["B_REF"], y=df_vert["SPREAD_PP"],
                    text=[f"{v:.2f}" if pd.notna(
                        v) else "" for v in df_vert["SPREAD_PP"]],
                    textposition="outside", marker_color="#1F4E79"))
                fig2.update_layout(
                    title=f"{fundo_sel} ‚Äì Spread ponderado ({data_ref})",
                    xaxis_title="V√©rtice (B)", yaxis_title="Spread (p.p.)",
                    height=520, plot_bgcolor="white")
                st.plotly_chart(fig2, use_container_width=True)
                st.table(
                    df_vert.set_index('B_REF').rename(
                        columns={"DIV1_ATIVO": "Œ£‚ÄØDIV1"})
                    .style.format({"TAX_POND": "{:.4f}",
                                   "NTNB_YIELD": "{:.4f}",
                                   "SPREAD_PP": "{:.2f}",
                                   "Œ£‚ÄØDIV1": "{:.0f}"}))

            # DEIXAR DUAS COLUNAS OPCIONAL. SE O USU√ÅRIOS ESCOLHER TER A VIS√ÉO DO SPREAD M√âDIO SEM PONDERA√á√ÉO MOSTRAR O GR√ÅFICO ABAIXO E A TABELA, SEN√ÉO MANTER O GR√ÅFICO E A TABELA ACIMA, MAS COMO DUAS COLUNAS EM VEZ DE UMA
            with col_tbl2:
                df_ref = base[(base["Fundo"] == fundo_sel) &
                              (base["DATA_DATE"] == data_ref)]

                # st.write(df_ref)

                if df_ref.empty:
                    st.info("Fundo sem ativos nessa data.")
                    return

                medias = (df_ref.groupby("B_REF", as_index=False)["TAX_INDIC"].mean()
                                .rename(columns={"TAX_INDIC": "TAX_MEAN"}))

                # Junta NTNB (√∫ltimo preg√£o <= data_ref)
                # ‚îÄ‚îÄ m√©dias por v√©rtice (dict para evitar Series vazios) ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
                tax_dict = (df_ref.groupby("B_REF")["TAX_INDIC"]
                            .mean()
                            .to_dict())                 # ex.: {'B25': 5.23, ...}

                # Somar os Div1_ATIVO por B_REF para cada fundo
                pesos_dict = df_ref.groupby(
                    "B_REF")["DIV1_ATIVO"].sum().reset_index()
                # st.write(pesos_dict)

                rows = []
                for b in vertices_disp:                         # garante todos os v√©rtices
                    taxa_mean = tax_dict.get(b, None)

                    ntb = nt_long[(nt_long["B_REF"] == b) &
                                  (nt_long["DATA"].dt.date <= data_ref)]
                    ntb_y = ntb.iloc[-1]["NTNB_YIELD"] if not ntb.empty else None

                    spread = (taxa_mean - ntb_y
                              if pd.notna(taxa_mean) and pd.notna(ntb_y) else None)

                    rows.append({"B_REF": b,
                                "TAX_MEAN": taxa_mean,
                                 "NTNB_YIELD": ntb_y,
                                 "SPREAD_PP": spread})

                df_vert = pd.DataFrame(rows)
                # Dropar Nones in Taxa_mean
                df_vert = df_vert.dropna(subset=["TAX_MEAN"])

                # gr√°fico de barras
                fig2 = go.Figure(go.Bar(
                    x=df_vert["B_REF"],
                    y=df_vert["SPREAD_PP"],
                    text=[f"{v:.2f}" if pd.notna(
                        v) else "" for v in df_vert["SPREAD_PP"]],
                    textposition="outside",
                    marker_color="#1F4E79"))
                fig2.update_layout(
                    title=f"{fundo_sel} ‚Äì Spread M√©dio por V√©rtice ({data_ref})",
                    xaxis_title="V√©rtice (B)",
                    yaxis_title="Spread (p.p.)",
                    height=520, plot_bgcolor="white")
                st.plotly_chart(fig2, use_container_width=True)

                # tabela
                st.table(
                    df_vert.set_index('B_REF').style.format({"TAX_MEAN": "{:.4f}",
                                                             "NTNB_YIELD": "{:.4f}",
                                                             "SPREAD_PP": "{:.2f}"})
                )

    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ 3.¬†GR√ÅFICO‚ÄØ3 ‚Äì S√âRIE 1‚ÄëN FUNDOS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    if show_g3:
        st.subheader("Gr√°fico‚ÄØ3¬†‚Äì Evolu√ß√£o do spread m√©dio ponderado")

        fundos_sel = st.sidebar.multiselect("Fundos para o‚ÄØGr√°fico‚ÄØ3:",
                                            fundos_disp,
                                            default=[fundos_disp[0]])
        if not fundos_sel:
            st.info("Selecione pelo menos um fundo para o Gr√°fico‚ÄØ3.")
            return

        fig3 = go.Figure()
        for fundo in fundos_sel:
            df_fund = base[base["Fundo"] == fundo].copy()

            # ‚ñº NOVA s√©rie usando _spread_fundo_dia ‚ñº
            serie = (df_fund.groupby("DATA_DATE", group_keys=False)
                     .apply(_spread_fundo_dia)
                     .reset_index(name="SPREAD_POND"))

            fig3.add_trace(go.Scatter(
                x=serie["DATA_DATE"], y=serie["SPREAD_POND"],
                mode="lines+markers", name=fundo))

        fig3.update_layout(
            height=480, plot_bgcolor="white",
            xaxis_title="Data", yaxis_title="Spread (p.p.)")
        st.plotly_chart(fig3, use_container_width=True)

        # (op√ß√£o de mostrar tabela resumida)
        if st.checkbox("Mostrar s√©rie num√©rica (todos os fundos)"):
            big_tbl = None
            for fundo in fundos_sel:
                df_fund = base[base["Fundo"] == fundo].copy()
                serie = (df_fund.groupby("DATA_DATE", group_keys=False)
                         .apply(_spread_fundo_dia)
                         .rename(fundo))
                big_tbl = pd.concat([big_tbl, serie], axis=1)
            st.dataframe(big_tbl.style.format("{:.2f}"))


def analisar_spreads_por_fundo(df_posicao_juros: pd.DataFrame):
    """
    ‚Ä¢ Calcula pesos =  Œ£ DIV1_ATIVO por B_REF dentro do(s) fundo(s)
    ‚Ä¢ Aplica esses pesos aos spreads B/DAP (df_spread_melt e df_spread_vert)
    ‚Ä¢ Reproduz a mesma UI de 'analisar_spreads', mas j√° ponderada
    """
    st.subheader("An√°lise ‚Äì Spreads ponderados por Fundo")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 0) ESCOLHA DE FUNDOS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    fundos_disp = sorted(df_posicao_juros["Fundo"].unique())
    fundos_sel = st.sidebar.multiselect(
        "Fundos:", fundos_disp, default=fundos_disp)
    if not fundos_sel:
        st.warning("Selecione ao menos um fundo.")
        return

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 1) PESOS DIV1 POR B_REF ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    # precisa do lookup (Ativo ‚Üí B_REF)
    if "df_spreads_af" not in st.session_state:
        st.session_state["df_spreads_af"] = load_spreads_afinvest()
    df_lookup = st.session_state["df_spreads_af"][["Ativo", "B_REF"]]

    pesos = (df_posicao_juros[df_posicao_juros["Fundo"].isin(fundos_sel)]
             .merge(df_lookup, on="Ativo", how="inner")
             .groupby("B_REF", as_index=False)["DIV1_ATIVO"].sum())
    st.write(df_posicao_juros[df_posicao_juros["Fundo"].isin(fundos_sel)])

    st.write(df_lookup, pesos)
    if pesos.empty:
        st.write("Nenhum ativo dos fundos escolhidos existe na planilha de spreads.")
        return

    pesos["peso"] = pesos["DIV1_ATIVO"] / pesos["DIV1_ATIVO"].sum()
    # dicion√°rio  { 'B25':0.17 , 'B35':0.22 , ... }

    w = dict(zip(pesos["B_REF"], pesos["peso"]))

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 2) OBT√âM SPREADS ORIGINAIS (j√° no session_state) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    if "df_spread_melt" not in st.session_state:
        dfm, dfv = _prep_spread_df("Dados/BBG - ECO DASH_te.xlsx")
        st.session_state["df_spread_melt"] = dfm
        st.session_state["df_spread_vert"] = dfv

    df_melt_full = st.session_state["df_spread_melt"].copy()
    df_vert_full = st.session_state["df_spread_vert"].copy()

    # Apenas v√©rtices que t√™m peso
    padrao = "|".join(sorted(w))                       # ex.: 'B25|B30|B35'
    df_melt_full = df_melt_full[
        df_melt_full["Tipo"].str.contains(padrao)
    ]
    df_vert_full = df_vert_full[
        df_vert_full["Vertice"].astype(str).isin([b[1:] for b in w])
    ]

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 3) SIDEBAR (igual √† fun√ß√£o original) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    with st.sidebar:
        st.write("---")
        st.markdown("## Filtros ‚Äì Spreads ponderados")
        # ‚îÄ‚îÄ se n√£o sobrou nenhum spread depois do filtro ‚Äòpadrao‚Äô
        if df_melt_full.empty:
            st.warning(
                "N√£o h√° spreads para os v√©rtices presentes nos fundos selecionados.")
            return

        min_date = df_melt_full["DATA"].min().date()
        max_date = df_melt_full["DATA"].max().date()

        col1, col2 = st.columns(2)
        start_date = col1.date_input("In√≠cio",  min_value=min_date,
                                     max_value=max_date, value=min_date)
        end_date = col2.date_input("Fim",     min_value=min_date,
                                   max_value=max_date, value=max_date)

        freq_map = {"Di√°ria": "D", "Semanal": "W", "Mensal": "M"}
        freq = st.selectbox("Frequ√™ncia", list(freq_map), 0)

    if start_date > end_date:
        st.warning("A data inicial √© posterior √† final ‚Äì ajuste o intervalo.")
        return

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 4) FILTRO DE PER√çODO & REAMOSTRAGEM ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    mask = df_melt_full["DATA"].dt.date.between(start_date, end_date)
    df_melt = df_melt_full[mask].copy()

    if freq != "Di√°ria":
        rule = freq_map[freq]
        wide = (df_melt.pivot(index="DATA", columns="Tipo", values="Spread")
                .resample(rule, label="right", closed="right")
                .median()
                .dropna(how="all"))
        df_melt = (wide.stack().rename("Spread").reset_index())
        df_melt["Data_Str"] = df_melt["DATA"].dt.strftime("%Y-%m-%d")

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 5)  C√ÅLCULO DO SPREAD PONDERADO ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    #   5.1  extrai label 'B25' do campo 'Tipo' (Spread B25/DAP25)
    df_melt["B_REF"] = df_melt["Tipo"].str.extract(r"(B\d{2})")
    #   5.2  aplica peso
    df_melt["PESO"] = df_melt["B_REF"].map(w)
    df_melt["Spread_Pond"] = df_melt["Spread"] * df_melt["PESO"]

    #   5.3  s√©rie agregada
    serie = (df_melt.groupby("DATA", as_index=False)["Spread_Pond"].sum()
             .assign(Data_Str=lambda x: x["DATA"].dt.strftime("%Y-%m-%d")))

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 6) GR√ÅFICO DE LINHA (unica curva) ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    fig_line = go.Figure(go.Scatter(
        x=serie["Data_Str"], y=serie["Spread_Pond"],
        mode="lines+markers+text",
        text=[f"{v:.2f}" if i % 5 == 0 else "" for i,
              v in enumerate(serie["Spread_Pond"])],
        textposition="top center",
        marker=dict(color="#1F4E79", size=6),
        name="Spread M√©dio Ponderado"))
    fig_line.update_layout(
        title="Evolu√ß√£o do Spread M√©dio Ponderado",
        xaxis_title="Data", yaxis_title="Spread (p.p.)",
        plot_bgcolor="white", height=450)
    st.plotly_chart(fig_line, use_container_width=True)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 7) BARRA POR V√âRTICE  (mesma data-ref da fun√ß√£o original)‚ïê
    # Reutiliza df_vert_full j√° filtrado no intervalo
    st.write(df_vert_full)
    df_vert = df_vert_full[
        df_vert_full["DATA"].dt.date.between(start_date, end_date)
    ].copy()

    if freq != "Di√°ria":
        rule = freq_map[freq]
        wide_v = (df_vert.pivot(index="DATA", columns="Vertice", values="Spread")
                  .resample(rule, label="right", closed="right")
                  .median()
                  .stack()
                  .rename("Spread")
                  .reset_index())
        df_vert = wide_v.assign(Vertice=lambda x: x["Vertice"].astype(int))

    # Sidebar ‚Äì escolha do dia/semana/m√™s de refer√™ncia
    # Ver se esse gr√°fico faz sentido ent√£o
    st.write('Ver se esse gr√°fico faz sentido')
    ordem = ["25", "26", "27", "28", "30", "32", "35", "40"]
    df_base = df_vert
    datas_disp = sorted(df_base["DATA"].dt.date.unique())

    with st.sidebar:
        if freq == "Di√°ria":
            data_ref = st.date_input("Data de refer√™ncia",
                                     value=datas_disp[-1],
                                     min_value=datas_disp[0],
                                     max_value=datas_disp[-1])
        else:
            rot = "Semana" if freq == "Semanal" else "M√™s"
            data_ref = st.selectbox(f"{rot} de refer√™ncia",
                                    datas_disp, index=len(datas_disp)-1)

    df_sel = df_base[df_base["DATA"].dt.date == data_ref]
    spread_map = dict(zip(df_sel["Vertice"].astype(str), df_sel["Spread"]))

    # aplica peso de cada v√©rtice
    y_vals = []
    for v in ordem:
        b = f"B{v}"
        if b in w and v in spread_map:
            y_vals.append(spread_map[v] * w[b])   # j√° ponderado
        else:
            y_vals.append(None)

    fig_bar = go.Figure(go.Bar(
        x=ordem, y=y_vals,
        text=[f"{x:.2f}" if x is not None else "" for x in y_vals],
        textposition="outside",
        marker_color="#1F4E79"))
    fig_bar.update_layout(
        title=f"Contribui√ß√£o por V√©rtice ‚Äì {data_ref:%d/%m/%Y}",
        xaxis=dict(title="V√©rtice (anos)", type="category"),
        yaxis=dict(title="Spread ponderado (p.p.)"),
        plot_bgcolor="white", height=550, showlegend=False)
    st.plotly_chart(fig_bar, use_container_width=True)

    # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê 8) MOSTRA TABELA DE PESOS ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    st.write("Pesos DIV1 utilizados:")
    st.dataframe(
        pesos[["B_REF", "peso", "DIV1_ATIVO"]]
        .rename(columns={"B_REF": "B", "peso": "Peso", "DIV1_ATIVO": "Œ£ DIV1"})
        .style.format({"Peso": "{:.1%}", "Œ£ DIV1": "{:.0f}"}))


###############################################################################
# (Demais fun√ß√µes utilit√°rias, CSS e main() seguem SEM altera√ß√µes relevantes,
#  apenas atualizando assinaturas onde plot_div1_layout foi chamado.)
###############################################################################

def add_custom_css():
    # CSS personalizado
    st.markdown(
        """
        <style>
        div[class="st-al st-bt st-bp st-bu st-bv st-bw st-bx st-by st-bz st-ak st-c0 st-c1 st-c2 st-bn st-c3 st-c4 st-c5 st-c6 st-c7 st-c8 st-c9"] input {
            color: black !important;  /* Altera a cor do texto */
        }
        div[data-baseweb="select"] div[class*="st-cy"] {
        color: black !important;
        }
        /* Altera o texto dentro da op√ß√£o selecionada do primeiro dropdown */
        div[data-baseweb="select"] div[class*="st-cy"] {
            color: black !important;
        }

        /* Altera o texto do input do segundo dropdown */
        div[data-baseweb="select"] input[role="combobox"] {
            color: black !important;
        }
        div[role="listbox"] div {
        color: black !important;
        }
        div[class*="st-cc"] {
            color: black !important;
        }
        div.st-cc.st-bn.st-ar.st-cd.st-ce.st-cf {
            color: black !important;
        }
        /* Altera a cor de texto dos itens de op√ß√£o (como "ACRC21") */
        div[data-baseweb="select"] div[role="option"] {
            color: black !important;
        }

         /* Alterar a cor de todo o texto na barra lateral */
        section[data-testid="stSidebar"] * {
            color: White; /* Cor padr√£o para textos na barra lateral */
        }

        div[class="stDateInput"] div[class="st-b8"] input {
            color: white;
        }
        div[role="presentation"] div {
            color: white;
        }

        div[data-baseweb="calendar"] button  {
            color:white;
        }
            
        /* Alterar a cor do texto no campo de entrada do st.number_input */
        input[data-testid="stNumberInput-Input"] {
            color: black !important; /* Define a cor do texto como preto */
        }

        input[data-testid="stNumberInputField"] {
            color: black !important; /* Define a cor do texto como preto */
        }

        /* Estiliza os bot√µes de incremento e decremento */
        button[data-testid="stNumberInputStepDown"], 
        button[data-testid="stNumberInputStepUp"] {
            color: black !important; /* Define a cor do √≠cone ou texto como preto */
            fill: black !important;  /* Caso o √≠cone SVG precise ser estilizado */
        }

        /* Estiliza o √≠cone dentro dos bot√µes */
        button[data-testid="stNumberInputStepDown"] svg, 
        button[data-testid="stNumberInputStepUp"] svg {
            fill: black !important;  /* Garante que os √≠cones sejam pretos */
        }
        
        /* Estiliza o fundo do container do multiselect */
        div[class="st-ak st-al st-bd st-be st-bf st-as st-bg st-bh st-ar st-bi st-bj st-bk st-bl"] {
            background-color: White !important; /* Altera o fundo para branco */
        }

        /* Estiliza o fundo do input dentro do multiselect */
        div[class="st-al st-bm st-bn st-bo st-bp st-bq st-br st-bs st-bt st-ak st-bu st-bv st-bw st-bx st-by st-bi st-bj st-bz st-bl st-c0 st-c1"] input {
            background-color: White !important; /* Altera o fundo do campo de entrada */
        }

        div[class="st-al st-bt st-bp st-bu st-bv st-bw st-bx st-by st-bz st-ak st-c0 st-c1 st-c2 st-bn st-c3 st-c4 st-c5 st-c6 st-c7 st-c8 st-c9"] input {
            color: black !important;  /* Altera a cor do texto */
        }
            /* Altera a cor de texto dos itens de op√ß√£o (como "ACRC21") */
        div[data-baseweb="select"] div[role="option"] {
            color: black !important;
        }

        /* Altera a cor de texto dos itens j√° selecionados no multiselect */
        div[data-baseweb="select"] div[class*="st-bm"] {
            color: black !important;
        }

        /* Estiliza o fundo do bot√£o ou elemento de "Escolher uma op√ß√£o" */
        div[class="st-cc st-bn st-ar st-cd st-ce st-cf"] {
            background-color: White !important; /* Altera o fundo do bot√£o de op√ß√£o */
        }

        /* Estiliza o √≠cone dentro do bot√£o de decremento */
        button[data-testid="stNumberInput-StepUp"] svg {
            color: black !important;
            fill: black !important;
        }
        button[data-testid="stNumberInput-StepDown"] svg {
            fill: black !important; /* Garante que o √≠cone seja preto */
        }

        div[data-testid="stNumberInput"] input {
            color: black; /* Define o texto como preto */
        }
        
        div[data-testid="stDateInput"] input {
            color: black;
        }
        div[class="st-al st-bt st-bp st-bu st-bv st-bw st-bx st-by st-bz st-ak st-c0 st-c1 st-c2 st-bn st-c3 st-c4 st-c5 st-c6 st-c7 st-c8 st-c9"] input {
            color: black !important;  /* Altera a cor do texto */
        }
        /* Altera a cor de texto dos itens de op√ß√£o (como "ACRC21") */
        div[data-baseweb="select"] div[role="option"] {
            color: black !important;
        }
        </style>
        """,
        unsafe_allow_html=True,
    )

    # JavaScript para aplicar zoom de 80%
    components.html(
        """
        <script>
            document.body.style.zoom = "60%";
        </script>
        """,
        height=0,
    )


if __name__ == "__main__":
    # CSS pessoal, carregamento de dados e roteamento principal ‚Äì inalterados
    add_custom_css()
    df_master = process_df()
    df_div1 = process_div01()

    st.sidebar.title("Escolha a vis√£o")
    # modo = st.sidebar.radio(
    #    "Modo de an√°lise",
    #    ["Analisar Ativo", "Analisar Fundo", "An√°lise Geral",
    #    "Analisar Spreads", "Analisar Spreads por Fundo",
    #    "Analisar Spreads Deb‚ÄëB","Analisar Spreads Deb-B2"])          # ‚Üê nova linha

    # ‚îÄ‚îÄ‚îÄ menu principal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
    modo = st.sidebar.radio(
        "Modo de an√°lise",
        ["Analisar Ativo", "Analisar Fundo", "An√°lise Geral",
         "Analisar Spreads"]      # ‚ùå removemos o item ‚ÄúAnalisar Spreads Deb-B2‚Äù
    )



    if modo == "Analisar Ativo":
        # assinatura original aceita apenas 2 args
        analisar_ativo(df_master, df_div1)
    elif modo == "Analisar Fundo":
        analisar_fundo(df_master, df_div1)
    elif modo == "An√°lise Geral":
        analisar_geral(df_master, df_div1)
    elif modo == "Analisar Spreads":
        # ‚îÄ‚îÄ sub-menu interno ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
        tipo_spread = st.sidebar.radio(
            "Tipo de spread",
            ["NTNB √ó DAP", "Deb√™ntures √ó NTNB-B"],
            key="sub_spread"
        )
        if tipo_spread == "NTNB √ó DAP":
            analisar_spreads()                     # ‚Ü©Ô∏é continua igual
        else:                                      # Deb√™ntures √ó NTNB-B
            if "df_carteira_recent" not in st.session_state:
                st.session_state["df_carteira_recent"] = load_carteira_recent()
            analisar_spreads_deb_b2(
                st.session_state["df_carteira_recent"])  # ‚Üê nova linha

    elif modo == "Analisar Spreads por Fundo":
        analisar_spreads_por_fundo(df_master)
    elif modo == "Analisar Spreads Deb‚ÄëB":
        analisar_spreads_deb_b(df_master)
    else:
        st.warning("Escolha uma op√ß√£o v√°lida.")
